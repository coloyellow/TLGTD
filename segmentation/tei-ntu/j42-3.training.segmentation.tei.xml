<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<page>41 <lb/></page>

			<front>圖書資訊學刊 第14卷第1期 (2016.6) 頁41-85 <lb/></front>
			
			<front>doi:10.6182/jlis.2016.14(1).041 <lb/></front>

			<front>同儕審查的起源、研究現況與展望 <lb/>History, Research, and Challenges: A Systematic Analysis of <lb/>Peer Review for Journals, Grants, and Faculty Appointments <lb/>黃慕萱 1 嚴竹蓮 2 <lb/>Mu-Hsuan Huang 1 , Chu-Lien Yen 2 <lb/>摘 要 <lb/>同儕審查是學術界進行科學探索時所採用的一項自律機制，幾乎已制度化地納入學術 <lb/>組織的運作之中，並普遍獲得學界人士的支持。基本上同儕審查的正當性是基於學術社群 <lb/>成員之間的信賴與誠信，在各項學術活動中以不同的作業模式分配有限資源，包括學術文 <lb/>獻出版、研究計畫獎助、大學教職聘用與升遷，以及學術成就獎勵等。但是同儕審查的運 <lb/>作方式迄今未臻完善，除了出現效用、效率，以及信度等問題外，許多研究亦已證實存在 <lb/>多種評審者偏見，因此有愈來愈多的學者主張對同儕審查進行持續性地檢驗與監督，以提 <lb/>升評審作業的品質與公平性。本文透過文獻分析論述同儕審查在學術領域的應用與研究， <lb/>首先說明同儕審查的定義、分類與優缺點，並以學術期刊稿件、獎助計畫，以及大學教職 <lb/>聘用 升遷之同儕審查為例，探討同儕審查的起源、發展與研究現況，最後分析同儕審查 <lb/>的國際合作及其與書目計量的關係。 <lb/>關鍵字： 同儕審查、書目計量 <lb/>1 國立臺灣大學圖書資訊學系暨研究所 <lb/>Department and Graduate Institute of Library and Information Science, National Taiwan University, <lb/>Taipei, Taiwan <lb/>2 中華民國外交部資訊及電務處 <lb/>Department of Archives, Information Management and Telecommunications, Ministry of Foreign <lb/>Affairs, Taipei, Taiwan <lb/>* 通訊作者Corresponding Author: 嚴竹蓮Chu-Lien Yen, E-mail: clyen01@mofa.gov.tw <lb/></front>

			<page>42 <lb/></page>

			<note place="headnote">Journal of Library and Information Studies 14:1 (June 2016) <lb/></note>

			<div type="annex">Extended Abstract <lb/></div>
			
			<front>Abstract <lb/>Peer review is a self-regulation mechanism for scientific inquiry. Institutionalized and <lb/>incorporated into the structure and operation of science, it has received considerable support in the <lb/>academic setting. The legitimacy of peer review is based on trust and integrity. In various ways, it <lb/>allocates scarce resources such as journal space, research funding, faculty recruitment, recognition, <lb/>and rewards for academic achievements. But there are growing indications that peer review has yet <lb/>to fulfill its potential functions, leading to negative assessments as to whether it is effective, efficient, <lb/>or reliable. Many studies have found links between potential sources of bias and judgments in peer <lb/>review and expressed reservations over the fairness of the process. It is, therefore, important that the <lb/>peer review process should be subjected to serious scrutiny and regular evaluation that would lead to <lb/>better quality and greater fairness. This study presents a systematic review of the empirical literature <lb/>on peer review of journal manuscripts, grant applications, and faculty appointments and promotions. <lb/>Historical and contextual information is provided as a basis for interpreting this review. Finally, the <lb/>authors discuss international recommendations for good practice in peer review and the potential and <lb/>problems of peer review and bibliometrics. <lb/>Keywords: Peer Review; Bibliometrics <lb/></front>
			
			<note place="footnote">Note. This extended English abstract is supplied by the authors. <lb/>To cite this article in APA format: Huang, M.-H., &amp; Yen, C.-L. (2016). History, research, and <lb/>challenges: A systematic analysis of peer review for journals, grants, and faculty appointments. <lb/>Journal of Library and Information Studies, 14(1), 41-85. doi: 10.6182/jlis.2016.14(1).041 [Text <lb/>in Chinese]. <lb/>To cite this article in Chicago format: Mu-Hsuan Huang and Chu-Lien Yen. &quot;History, <lb/>research, and challenges: A systematic analysis of peer review for journals, grants, and faculty <lb/>appointments.&quot; Journal of Library and Information Studies 14, no. 1 (2016): 41-85. doi: 10.6182/ <lb/>jlis.2016.14(1).041 [Text in Chinese]. <lb/>1. Introduction <lb/>Peer review is a relatively new topic of <lb/>research in the contemporary academic domain. <lb/>It was initially used as an aid to scientific inquiry, <lb/>to allow scientists to assess the quality of specific <lb/>pieces of scientific research, in order to generate <lb/>trustworthy and valid knowledge. Many scholars <lb/>trace the origins of peer review back to the <lb/>founding in 1665 of the journal Philosophical <lb/>Transactions by the Royal Society of London, <lb/>England. At that time the content of each issue <lb/>would be reviewed by members of the Society <lb/>before publication, and this has been seen as the <lb/>fountainhead of journal peer review (Burnham, <lb/>1990; Kronick, 1990; Lock, 1985; Rennie, 2003; <lb/>Spier, 2002a). Later, the scope of application of <lb/>peer review gradually expanded, and it became one <lb/>of the main mechanisms for the allocation of limited <lb/>funding resources and for faculty appointments and <lb/>promotions in higher education (Bornmann, 2011a; <lb/>Frodeman, Holbrook, &amp; Mitcham, 2012; Kronick, <lb/>1990; Langfeldt &amp; Kyvik, 2011). <lb/></note>

			<page>43 <lb/></page>

			<note place="headnote">Extended Abstract <lb/></note>

			<div type="annex">For more than three centuries peer review <lb/>has been valued in academia, but there have also <lb/>been many voices raised in criticism: numerous <lb/>scholarly articles have questioned the true <lb/>effectiveness of peer review, have criticized it as <lb/>costly and time-consuming, and have identified <lb/>signs of unfairness in the evaluation process <lb/>(Abdoul, Perrey, Amiel, et al., 2012; Bornmann, <lb/>2011a; Fang, 2011; Lee, Sugimoto, Zhang, <lb/>&amp; Cronin, 2013; Rennie, 2003; Sandström <lb/>&amp; Hällsten, 2007; Wenneras &amp; Wold, 1997; <lb/>Wood &amp; Wesseley, 2003). Nevertheless, most <lb/>scholars continue to see the need to maintain this <lb/>mechanism, because the possible alternatives <lb/>are yet more controversial. Some researchers <lb/>have even drawn a comparison with Churchill&apos;s <lb/>description of democracy as the worst form of <lb/>government, except all the other forms that have <lb/>been tried (Harley, Acord, Earl-Novell, Lawrence, <lb/>&amp; King, 2010; Ismail, Farrands, &amp; Wooding, <lb/>2009; Kostoff, 2004; Rennie, 1986; Sieber, 2006). <lb/>W h i l e a c a d e m i a h a s l o n g r e c o g n i z e d <lb/>imperfections in the operation of peer review, it <lb/>was not until around the 1980s that the need for <lb/>rational scrutiny of peer review gradually began to <lb/>gain attention. To date, empirical research on peer <lb/>review has mostly concentrated on the review of <lb/>journal manuscripts, followed next by that of grant <lb/>applications (Bornmann, 2011a; Demicheli &amp; Di <lb/>Pietrantonj, 2007; Jefferson, Rudin, Brodney-<lb/>Folse, &amp; Davidoff, 2007; Weller, 2002; Wood <lb/>&amp; Wessely, 2003); there has been little research <lb/>into peer review for faculty appointments (Miller, <lb/>1978; Weiser, 2012). In a review article on journal <lb/>and grant peer review during the preceding <lb/>decade, Bornmann (2011a) found that the bulk of <lb/>such research examined issues of trustworthiness <lb/>and fairness; there was relatively little examination <lb/>of the predictive validity of peer review. <lb/>In addition to scholars&apos; approaching peer <lb/>review as a branch of academic knowledge, and <lb/>constructing values and orientations for related <lb/>scientific research, organizations that make use <lb/>of peer review have also been actively engaging <lb/>in international exchange, including publishing <lb/>basic operational standards or practice guides for <lb/>peer review, in order to improve the quality of <lb/>evaluation and enhance its credibility. However, <lb/>as yet there has been little research that confirms <lb/>the validity of peer review, so that there is a lack <lb/>of firm correlation between review outcomes and <lb/>levels of contribution to science. Some scholars have <lb/>suggested that peer review should be reinforced <lb/>by the use of bibliometrics, but how these two <lb/>assessment methods can be integrated is an issue that <lb/>still awaits academic debate and research. <lb/>2. Definition, Categories, and <lb/>Pros and Cons of Peer Review <lb/>&quot;Social psychology conceptualizes the peer <lb/>review process as a social judgment process of <lb/>individuals in a small group (for example, one <lb/>or more reviewers and one or more editors of a <lb/>disciplinary in-group in manuscript reviewing)&quot; <lb/>(Bornmann, 2011a, p. 200). Some researchers have <lb/>likened peer review to the technique of &quot;grading <lb/>the grain&quot; in agricultural produce markets. <lb/>However, the grading done by peer review is <lb/>not a single procedure, but a set of flexible and <lb/>adjustable mechanisms. Each organization that <lb/>uses peer review has a different way of operating, <lb/>and there may even be differences among different <lb/>departments within the same organization (Chubin <lb/>&amp; Hackett, 2003; Cole &amp; Cole, 1973; Kostoff, <lb/></div>

			<page>44 <lb/></page>

			<note place="headnote">Journal of Library and Information Studies 14:1 (June 2016) <lb/></note>

			<div type="annex">2004; Research Councils UK [RCUK], 2006; <lb/>Research Information Network [RIN], 2010). <lb/>The scope of application of peer review in <lb/>academia is very broad, and peer review has been <lb/>subcategorized in different ways, mainly based on <lb/>the target of evaluation (Harley &amp; Acord, 2011; <lb/>Parliamentary Office of Science and Technology <lb/>[POST], 2002; RIN, 2010). In this study, we divide <lb/>peer review into three major types: peer review of <lb/>publications, peer review for funding purposes, and <lb/>peer review of cumulative achievement. <lb/>In theory, the advantages of peer review appear <lb/>almost self-evident: Scientists&apos; peers are assumed <lb/>to be naturally the people most able to put forward <lb/>correct opinions and suggestions on their research <lb/>(Chubin &amp; Hackett, 1990). Proponents of peer <lb/>review believe that its effects are at least better <lb/>than those achieved by self-restraint on the part <lb/>of scientists, and that it can provide constructive <lb/>rational assessment in order to improve the <lb/>quality of research (Bornmann &amp; Daniel, 2005; <lb/>Nickerson, 2005). Many studies have indicated <lb/>broad acceptance of and high levels of support <lb/>for peer review in academic circles (Bertout &amp; <lb/>Schneider, 2004; Boden et al., 1990; Fletcher &amp; <lb/>Fletcher, 2003; Gibson, Spong, Simonsen, Martin, <lb/>&amp; Scott, 2008; POST, 2002; Royal Society, 1995; <lb/>Ware &amp; Monkman, 2008). However, peer review <lb/>has also attracted much criticism, for example <lb/>that the review process is time-consuming and <lb/>costly; that the effectiveness of peer review is not <lb/>readily demonstrable; that there is a low degree <lb/>of reliability between evaluators; and that review <lb/>outcomes are unfair, fail to encourage innovation, <lb/>and are unfavorable to young scientists. <lb/>Today, peer review is a mechanism of self-<lb/>regulation in academic communities, and has <lb/>been closely incorporated into the operations of <lb/>academic organizations. Yet many scholars believe <lb/>that peer review has inherent limitations. <lb/>I n t h i s s t u d y w e p r e s e n t e i g h t m a j o r <lb/>characteristics of peer review: the difficulty of <lb/>defining peers; the conflicted role of the peer; <lb/>flexibility in the interpretation of review criteria; <lb/>the need for both originality and skepticism to <lb/>assure the quality of science; compromise between <lb/>multiple goals; decision-making by a small <lb/>number of people behind closed doors; challenges <lb/>arising from the demands for both academic <lb/>autonomy and social responsibility; and the need <lb/>for balance between trust and oversight. These <lb/>are all issues that need to be confronted when <lb/>organizing peer review activities. <lb/>3. Origins and Development of <lb/>Peer Review <lb/>Peer review is a core element of the scientific <lb/>domain. It plays a crucial role in the publication <lb/>of journal articles, in the allocation of funding <lb/>resources, and in the recruitment and career <lb/>progression of university faculty members. <lb/>However, while the history of journal peer <lb/>review can be traced back to the publication of <lb/>Philosophical Transactions by the Royal Society <lb/>of London from the 17th century onward, grant <lb/>peer review and faculty appointment peer review <lb/>are mechanisms that developed independently in <lb/>the 19th and 20th centuries in response to practical <lb/>operational needs. Today, peer review mechanisms <lb/>are widely used by research funding bodies and <lb/>institutes of higher education (Bornmann, 2011a; <lb/>Weiser, 2012). <lb/>The modern development of peer review has <lb/>been influenced by bibliometrics. The impact <lb/></div>

			<page>45 <lb/></page>

			<note place="headnote">Extended Abstract <lb/></note>

			<div type="annex">factor proposed by Garfield and Sher (1963) has <lb/>given concrete expression to the validity of journal <lb/>peer review. In the late 20th century, various <lb/>bibliometric indicators, in particular citation <lb/>analysis, gradually became important points of <lb/>reference for evaluating the research performance <lb/>of individuals and institutions, so that through <lb/>the intermediary of bibliometrics, journal peer <lb/>review once again indirectly became an important <lb/>factor influencing funding allocation and faculty <lb/>appointments (Harley &amp; Acord, 2011; Harley et <lb/>al., 2010; van Arensbergen, van der Weijden, &amp; <lb/>van den Besselaar, 2014a). In addition, for journal <lb/>readers in the age of the information explosion, <lb/>journal peer review&apos;s function of quality control <lb/>over the scientific literature makes it a reliable <lb/>guarantee of reading quality. <lb/>Through more than 300 years of development, <lb/>journal peer review has become the gatekeeper of <lb/>scientific knowledge, and is greatly valued by the <lb/>scientific community. But there are also voices <lb/>of criticism and calls for reform, and with the <lb/>development of electronic journal publishing and <lb/>continued improvements in its quality, along with <lb/>changing reading habits, many scholars believe <lb/>that in the not too distant future, revolutionary <lb/>changes may take place in journal peer review. <lb/>The development of grant peer review, on the <lb/>other hand, is closely related to expansion in the <lb/>functions of government. Particularly in the 20th <lb/>century, various countries began to devote funds <lb/>to supporting scientific research, and peer review <lb/>became one of the major mechanisms by which <lb/>governments allocate funding (Burnham, 1990; <lb/>Frodeman et al., 2012). At present, important <lb/>issues in grant peer review include the evaluation <lb/>of indicators of social impact and of innovation, <lb/>with both presenting difficulties in selecting peers <lb/>as well as in defining review criteria (Bell, Shaw, <lb/>&amp; Boaz, 2011; van der Meulen &amp; Rip, 2000). <lb/>As for faculty appointments peer review, <lb/>in an environment of expansion in university <lb/>education and the systematization of faculty <lb/>recruitment, this type of peer review has gradually <lb/>become the arbiter of scholars&apos; access to campus <lb/>teaching positions (Snodgrass, 2006; Weiser, <lb/>2012). In faculty appointments peer review, there <lb/>is a general issue of overemphasizing research <lb/>(Fairweather, 2005; Greenbank, 2006; Kreber, <lb/>2002; Pratt, 1997) and undervaluing teaching. In <lb/>recent years many countries have taken note of <lb/>this phenomenon and have actively adjusted <lb/>their higher education policies to encourage <lb/>high-quality teaching, in order to promote a <lb/>better balance between research and teaching <lb/>(Hénard, 2010). <lb/>4. Current Status of Peer Review <lb/>Research <lb/>Peer review is a mechanism for the allocation <lb/>of scarce resources in academia, yet its processes <lb/>are confidential in nature and there are few clues <lb/>to them in the public domain. It was not until <lb/>around the 1980s that peer review began to be <lb/>subjected to a greater degree of rational scrutiny <lb/>(Chubin &amp; Hackett, 1990; Rennie, 2003; Weller, <lb/>2002). To date, research into peer review has <lb/>mainly concentrated on peer review of journal <lb/>manuscripts and grant applications; there has been <lb/>very little investigation of peer review for faculty <lb/>appointments and promotion in higher education. <lb/>H o w e v e r, n u m e r o u s r e s e a r c h e r s h a v e <lb/>observed that in the great majority of the related <lb/>literature the methodology is weak and the <lb/></div>

			<page>46 <lb/></page>

			<note place="headnote">Journal of Library and Information Studies 14:1 (June 2016) <lb/></note>

			<div type="annex">causal reasoning tenuous, and that the great <lb/>diversity of research results makes it difficult <lb/>to reach general conclusions. They suggest that <lb/>such studies can be strengthened by using meta-<lb/>analysis or experimental research (Bornmann, <lb/>2011a; Bornmann, Nast, &amp; Daniel, 2008; De <lb/>Vries, Marschall, &amp; Stein, 2009; Demicheli &amp; Di <lb/>Pietrantonj, 2007; Jefferson et al., 2007). Marsh, <lb/>Jayasinghe and Bond (2011) suggest that in <lb/>addition to meta-analysis of secondary data from <lb/>the literature, there is also a need for large-scale <lb/>research on primary data from the peer review <lb/>process itself. <lb/>The development of journal peer review is <lb/>being impacted by the Internet and electronic <lb/>publishing. Some journal publishers and <lb/>research institutions have taken the initiative <lb/>to trial new forms of evaluation, such as pre-<lb/>publication peer review, post-publication peer <lb/>review, and open peer review, in the hope <lb/>of establishing as soon as possible the most <lb/>appropriate mode of evaluation for journal <lb/>manuscripts in the digital age (Borgman, 2007; <lb/>Bornmann &amp; Daniel, 2010; Bornmann, Marx, <lb/>S c h i e r, T h o r, &amp; D a n i e l, 2010; F o r d, 2013; <lb/>Odlyzko, 1996; van Rooyen, Delamothe, &amp; <lb/>Evans, 2010). <lb/>In the field of research into grant peer review, <lb/>with the trends toward open access to government <lb/>information and toward government performance <lb/>management, there has been much progress <lb/>in recent years. More and more government <lb/>funding agencies are willing to make data on the <lb/>evaluation process accessible to researchers, so <lb/>that scholars are no longer limited to analyzing <lb/>only evaluation outcomes, but can also analyze <lb/>and compare different stages of the peer review <lb/>process in detail (Bornmann, Leydesdorff, &amp; van <lb/>den Besselaar, 2010). <lb/>Although there has been little research into <lb/>faculty appointments peer review, more and more <lb/>scholars are giving attention to its objectivity <lb/>and fairness. ACUMEN (Academic Careers <lb/>Understood through Measurement and Norms), <lb/>funded under the European Commission&apos;s Seventh <lb/>Framework Programme, integrates the three <lb/>evaluation methods of peer review, bibliometrics, <lb/>and webometrics to create a framework-<lb/>the ACUMEN Portfolio-for the evaluation <lb/>of individual academic performance, and the <lb/>ACUMEN Consortium has published detailed <lb/>practice guidelines for the use of organizations <lb/>responsible for funding allocations and faculty <lb/>appointments. In an ACUMEN Portfolio, the first <lb/>part presents the candidate&apos;s own career narrative, <lb/>while the following three parts present indicators <lb/>of the candidate&apos;s expertise, output, and impact <lb/>(ACUMEN Consortium, 2014; Tatum &amp; Wouters, <lb/>2013). <lb/>5. Future Development of <lb/>Peer Review <lb/>In the great majority of countries, the <lb/>operating methods of peer review are not subject <lb/>to statutory regulation, but are decided by the <lb/>user organizations themselves. There may be <lb/>explicit practice guidelines, or evaluation may <lb/>be conducted according to established internal <lb/>procedures; the methods employed by different <lb/>institutions are highly diverse (Bornmann, 2011a; <lb/>General Accounting Office, 1999; Organisation <lb/>for Economic Co-operation and Development, <lb/>2011a; Rennie, 2003; Weiser, 2012; Weller, 2002; <lb/>Wood &amp; Wessely, 2003). <lb/></div>

			<page>47 <lb/></page>

			<note place="headnote">Extended Abstract <lb/></note>

			<div type="annex">However, for many years peer review users in <lb/>various countries have also actively engaged in <lb/>international exchange, sharing their experience <lb/>in order to improve the quality and credibility of <lb/>peer review. Such international collaboration has <lb/>already borne fruit in the areas of both journal peer <lb/>review and grant peer review, and some scholars <lb/>have also advocated international collaboration <lb/>between institutes of higher education to jointly <lb/>define basic evaluation indicators for faculty <lb/>appointments peer review (Harley &amp; Acord, 2011; <lb/>Weiser, 2012). <lb/>In addition to conducting research into peer <lb/>review, the academic world has also been actively <lb/>seeking improvements and alternative solutions. <lb/>In recent years, many innovative methods have <lb/>emerged in journal peer review, which is showing <lb/>diverse development. In the areas of grant peer <lb/>review and faculty appointments peer review, <lb/>the aspect that most often provokes debate is the <lb/>competitive-cooperative relationship between peer <lb/>review and bibliometrics. <lb/>Some scholars believe that the use of a broad <lb/>and diverse range of bibliometric indicators <lb/>is conducive to enhancing the rationality <lb/>and transparency of peer review (Bornmann, <lb/>2011b, 2013a; van Raan, 2005). Geisler (2001) <lb/>observed that the combined use of peer review <lb/>and bibliometrics enables peer review decisions <lb/>to be no longer merely the subjective opinions <lb/>of the evaluators, but introduces objective <lb/>quantitative indicators. However, how to <lb/>appropriately incorporate the quantitative data <lb/>of bibliometrics into different and diverse peer <lb/>review mechanisms presents a major challenge to <lb/>the academic world. <lb/>6. Conclusion <lb/>Among all human activities, scientific <lb/>research may be one of those most subject to <lb/>benchmarking and evaluation (Laloë &amp; Mosseri, <lb/>2009), both in order to assure the quality of <lb/>research and as a mechanism for allocating scarce <lb/>academic resources. But peer review has inherent <lb/>limitations. On the one hand, as a human activity <lb/>it may easily be affected by human weaknesses <lb/>or biases; and on the other hand reviewers wield <lb/>immense power, but emphasize confidentiality <lb/>(Geisler, 2000; Wenneras &amp; Wold, 1997; Ziman, <lb/>2000), and so attract criticism of &quot;black box&quot; <lb/>operations. Some scholars have even asserted that <lb/>the only reason for continuing to use peer review <lb/>is the lack of a better alternative (Kostoff, 2004; <lb/>Rennie, 1986; Sieber, 2006). <lb/>From the perspective of the spirit of academic <lb/>autonomy, the legitimacy of peer review is <lb/>based in mutual trust and honesty between <lb/>members of the academic community. The British <lb/>Academy&apos;s (2007) report on peer review points <lb/>out that when reviewing documents, reviewers <lb/>may come into contact with their peers&apos; original <lb/>data sets, new empirical results, or innovative <lb/>conceptual frameworks. In the business world, <lb/>such information would be regarded as trade <lb/>secrets, but in the academic domain evaluators&apos; <lb/>act as part of the scientific regulatory system, and <lb/>their ultimate goal is to rapidly and effectively <lb/>disseminate research results. Therefore evaluators&apos; <lb/>integrity is of tremendous importance. However, <lb/>numerous studies have demonstrated that <lb/>various biases exist among evaluators, that there <lb/>is too little consistency among evaluators, and <lb/>that the effectiveness of evaluation is difficult <lb/>to demonstrate. Thus there is a need to improve <lb/></div>

			<page>48 <lb/></page>

			<note place="headnote">Journal of Library and Information Studies 14:1 (June 2016) <lb/></note>

			<div type="annex">the fairness, rationality, and transparency of <lb/>peer review. <lb/>Today, peer review is widely valued in <lb/>academia, and has become the main referee <lb/>o f v a r i o u s k i n d s o f a c a d e m i c a c t i v i t y. <lb/>However, academic disciplines are becoming <lb/>increasingly specialized and complex, and <lb/>t h e r e s e a r c h p o p u l a t i o n i s g r o w i n g e v e r <lb/>larger, yet there has been no great increase in <lb/>academic resources. <lb/>In these circumstances, competition will grow <lb/>increasingly intense, and thus it seems likely <lb/>that research into peer review will attract ever <lb/>greater attention. This growing competition is <lb/>evidenced by the facts that today acceptance rates <lb/>for manuscripts submitted to many leading peer-<lb/>reviewed journals are in single figures, and that <lb/>rates of funding allocation by government and <lb/>private-sector funding organizations in various <lb/>countries are also trending downward year by year <lb/>(National Institutes of Health, 2013; National <lb/>S c i e n c e F o u n d a t i o n, 2011; P o w e l l, 2010; <lb/>RCUK, 2006). Moreover, there has also been <lb/>criticism regarding the fairness of evaluation <lb/>methods used for faculty appointments and <lb/>promotion in higher education. Therefore in <lb/>the future peer review practice will inevitably <lb/>face increasing questions and challenges <lb/>from the outside world, and establishing a <lb/>mechanism for continual supervision, scrutiny <lb/>and improvement should be a direction for <lb/>concerted effort within academia (Bornmann &amp; <lb/>Daniel, 2008; Callaham, 2003; De Vries et al., <lb/>2009; Gluckman, 2012; Godlee &amp; Jefferson, <lb/>2003; H e n l y &amp; D o u g h e r t y, 2009; H o j a t, <lb/>Gonnella, &amp; Caelleigh 2003; Langfeldt, 2001; <lb/>Rennie, 2003). <lb/></div>
			
			<body>壹、 前言 <lb/>「同儕審查」(peer review)是當代學 <lb/>術領域中一個比較新的研究主題，它原本用 <lb/>以輔助科學探索，容許科學家運用它來評判 <lb/>某一特定科學研究的品質，以產生具有信度 <lb/>與效度的知識。之後同儕審查的應用範圍逐 <lb/>漸擴大，成為學術界分配有限資源的主要機 <lb/>制之一，在期刊文獻出版、獎助資源分配， <lb/>以及大學教職的聘用與升遷上都扮演著關鍵 <lb/>角色(Bornmann, 2011b; Frodeman, Holbrook, <lb/>&amp; Mitcham, 2012; Kronick, 1990; Langfeldt &amp; <lb/>Kyvik, 2011)。近半個世紀以來，同儕審查的 <lb/>效用(effectiveness)、效率(efficiency)、信 <lb/>度(reliability)，以及公平性(fairness)等受 <lb/>到多方質疑，有關同儕審查的研究也因此日益 <lb/>受到重視，研究的廣度與深度亦逐漸增加，而 <lb/>成為一個獨立且益形重要的學門。 <lb/>同 儕 審 查 相 應 的 英 文 同 義 詞 除 了 <lb/>peer review之外，還包括peer advice、peer <lb/>evaluation、peer judgement、peer censorship、 <lb/>merit review，以及refereeing等(Chubin &amp; <lb/>Hackett, 1990)。中文也有不同的說法，例如同 <lb/>儕審查、同儕互評、同儕評論、同儕評鑑、同 <lb/>儕評估、同行評議、同行評審，以及同行評閱 <lb/>等，本研究將採用「同儕審查」做為前述中、 <lb/>英文含義的通用詞彙。 <lb/>許 多 學 者 認 為 同 儕 審 查 可 上 溯 至 1 6 6 5 <lb/>年英國倫敦皇家學會(R o y a l S o c i e t y o f <lb/>London)創辦的《哲學學報》(Philosophical <lb/>Transactions)，當時每期學報在出刊前，均 <lb/>須經由學會會員審查內容，而被視為期刊同儕 <lb/></body>

			<page>49 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>審查的濫觴(Burnham, 1990; Kronick, 1990; <lb/>Lock, 1985; Rennie, 2003; Spier, 2002a)。獎 <lb/>助同儕審查的發展則與政府的職能擴張息 <lb/>息相關，尤其在20世紀，各國政府開始編列 <lb/>預算支持科學研究，同儕審查就成為政府獎 <lb/>助經費分配的重要機制之一(Burnham, 1990; <lb/>Frodeman et al., 2012)。至於大學教職聘用 <lb/>升遷同儕審查是在大學教育普及化與教職聘 <lb/>用制度化的環境下，逐漸成為學者進入校 <lb/>園任教的仲裁者(Snodgrass, 2006; Weiser, <lb/>2012)。到了20世紀後期，英美等國政府強 <lb/>調科學管理，積極主導國家科學發展方向， <lb/>同儕審查遂進一步成為科技政策制定及教研 <lb/>機構評鑑的重要工具，而運作方式與評審標 <lb/>準也更為多元(Frodeman &amp; Briggle, 2012; <lb/>Guston, 2003; Organisation for Economic Co-<lb/>operation and Development [OECD], 2011a, <lb/>2011b; Whitley &amp; Gläser, 2007)。 <lb/>300多年來，同儕審查受到學術界的 <lb/>重視，日益擴大應用範圍，但是批評聲浪 <lb/>亦 眾 ， 許 多 文 獻 質 疑 同 儕 審 查 的 真 實 效 <lb/>用、批評其過程耗錢費時，並且發現評審 <lb/>不公的現象，包括機構(institutional)偏 <lb/>見、交情(c r o n y i s m)偏見、年齡偏見、 <lb/>性別偏見、國籍偏見、非英語母語偏見、 <lb/>保守(conservative)偏見、學派偏見、學 <lb/>術產出(p r o d u c t i v i s m)偏見，以及審察 <lb/>先後順序偏見等(Abdoul, Perrey, Amiel, et <lb/>al., 2012; Bornmann, 2011b; Fang, 2011; Lee, <lb/>Sugimoto, Zhang, &amp; Cronin, 2013; Rennie, <lb/>2003; Sandström &amp; Hällsten, 2007; Wenneras &amp; <lb/>Wold, 1997; Wood &amp; Wesseley, 2003)。儘管 <lb/>如此，大部分學者依然認為有必要維持這個 <lb/>機制，因為其他替代方案的爭議性更大；有 <lb/>些學者甚至將同儕審查類比為自由世界的民 <lb/>主制度，是不好機制中的最佳選項(Harley, <lb/>Acord, Earl-Novell, Lawrence, &amp; King, 2010; <lb/>Ismail, Farrands, &amp; Wooding, 2009; Kostoff, <lb/>2004; Rennie, 1986; Sieber, 2006)。 <lb/>雖然學術界早已認知到同儕審查作業 <lb/>的不完美，但是直到1980年代前後，同儕審 <lb/>查的理性檢驗才逐漸受到重視，1989年期 <lb/>刊同儕審查開始定期舉辦研討會，也帶動 <lb/>了一股研究風潮(Chubin &amp; Hackett, 1990; <lb/>Rennie, 2003; Weller, 2002)。目前同儕審查 <lb/>的實徵研究大多以期刊稿件為主，獎助計 <lb/>畫次之(Bornmann, 2011b; Demicheli &amp; Di <lb/>Pietrantonj, 2007; Jefferson, Rudin, Brodney-<lb/>Folse, &amp; Davidoff, 2007; Weller, 2002; Wood <lb/>&amp; Wesseley, 2003)，大學教職聘用 升遷同儕 <lb/>審查的研究不多(Miller, 1978; Weiser, 2012)。 <lb/>Bornmann(2011b)回顧近十餘年的期刊及獎 <lb/>助同儕審查實徵研究，其中大多數為信度及公 <lb/>平性議題，預期效度的研究較少。 <lb/>除了學術界將同儕審查視為一門學術 <lb/>知識，為其建構科學研究的價值與方向外， <lb/>同儕審查的主事機構也積極進行國際交流， <lb/>合作出版同儕審查的基本作業規範或操作指 <lb/>南，以強化評審品質並提升公信力。此外在 <lb/>網路科技發達之後，期刊同儕審查也出現許 <lb/>多創新作法，例如預印(pre-publication) <lb/>同儕審查、出版後(post-publication)同儕 <lb/></body>

			<page>50 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>審查，以及公開(open)同儕審查等，目的 <lb/>都在強化評審作業的公平性與透明性。不過 <lb/>直到今天，同儕審查的效度依然少有研究證 <lb/>實，使得評審結果與科學貢獻度之間缺乏堅 <lb/>實的關聯性；有些學者建議以書目計量加以 <lb/>補強，但是如何整合這兩種評鑑方法，仍是 <lb/>學術界有待討論與研究的議題。 <lb/>貳、 同儕審查的定義、分類與 <lb/>優缺點 <lb/>一、 同儕審查的定義與分類 <lb/>社會心理學家將同儕審查的過程概念 <lb/>化，稱之為「在小團體中，針對個人進行 <lb/>社會評價的過程，例如期刊編輯或評審者 <lb/>審查稿件(Bornmann, 2011b, p. 200)。」 <lb/>有 些 學 者 將 同 儕 審 查 類 比 為 農 產 市 場 的 <lb/>穀 物 分 級 技 術 ， 不 過 同 儕 審 查 的 分 級 並 <lb/>非單一程序，而是一組有彈性且可調整的 <lb/>機制，各個主事機構有不同的作業方式， <lb/>甚至同一機構的不同單位亦可能有所差異 <lb/>(Chubin &amp; Hackett, 2003; Cole &amp; Cole, 1973; <lb/>Kostoff, 2004; Research Councils UK [RCUK], <lb/>2006; Research Information Network [RIN], <lb/>2010)。 <lb/>以下列舉兩則學術界經常引用的同儕審 <lb/>查定義，一者就運作層面來看：「Michael <lb/>Gibbons與Luke Georghiou認為同儕審查是某 <lb/>一特定領域的專家，對於相同或相近領域之 <lb/>其他科學家的研究作品，進行科學特定面向 <lb/>(如研究品質)的專業價值判斷。其前提係 <lb/>基於評審專家必須對領域的認知發展、研究 <lb/>方向，以及研究社群有充足的知識(OECD, <lb/>2011a, p. 1)。」一者強調目的與應用： <lb/>「同儕審查是一套科學研究的品質評價機 <lb/>制，科學界利用同儕審查來確認研究程序的 <lb/>正確性及推論的合理性，並根據評審結果分 <lb/>配有限資源，例如期刊版面、獎助名額、 <lb/>學術聲望與特殊榮譽等(Chubin &amp; Hackett, <lb/>1990, pp. 1-2)。」 <lb/>同儕審查在學術界的應用範圍甚廣， <lb/>分類方式亦不相同。英國人文社會科學院 <lb/>(The British Academy)將同儕審查分為兩 <lb/>個層級，第一級同儕審查是直接針對科學家 <lb/>的研究產出進行評審，例如期刊同儕審查及 <lb/>獎助同儕審查等。而若只是在評審過程中 <lb/>參考第一級同儕審查的結果，則屬於第二 <lb/>級同儕審查，例如高等教育機構評鑑或世界 <lb/>大學評鑑等，近年來第二級同儕審查的應用 <lb/>已有益形增加的趨勢(The British Academy, <lb/>2007)。Frodeman等人(2012)則依據評審 <lb/>的用途將同儕審查區分為三類，其一為預期 <lb/>性用途，期刊同儕審查及獎助同儕審查均屬 <lb/>此類，評審者不但要審查期刊稿件或獎助計 <lb/>畫的科學品質，還須顧及評審結果的預期效 <lb/>度；其二為反省性用途，主要檢驗學術領域 <lb/>所採行的某種制度是否達到預訂目標，例 <lb/>如期刊品質評鑑或學術機構評鑑等；其三 <lb/>為綜合性用途，結合預期性及反省性兩種 <lb/>用途，例如大學教職的聘用 升遷同儕審 <lb/>查，評審者除了回溯受評者的過去成就， <lb/>也必須預測其未來的表現。 <lb/></body>

			<page>51 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>比較普遍採用的分類法是以評審標的 <lb/>物為基準，研究者綜整為三類：(一)出版品 <lb/>同儕審查：包括文獻類出版品(如期刊文獻 <lb/>及專書等)及非文獻類出版品(如紀錄片、 <lb/>資料庫、網站，以及電腦軟體等)的同儕審 <lb/>查；(二)獎助同儕審查：包括獎助計畫及獎 <lb/>學金的同儕審查；(三)成就同儕審查：評鑑 <lb/>個人、團隊、部門或機構的學術表現，並 <lb/>依據評審結果分配資源或獎勵，包括大學 <lb/>教職聘用 升遷同儕審查、學術榮譽或獎 <lb/>項同儕審查，以及教育暨研究機構評鑑等 <lb/>(Harley &amp; Acord, 2011; Parliamentary Office <lb/>of Science and Technology [POST], 2002; <lb/>RIN, 2010)。 <lb/>二、 同儕審查的優缺點 <lb/>理論上同儕審查的優點似乎不言自明， <lb/>科學家的同儕當然是最能夠對其研究提出 <lb/>精確看法與建議的人(Chubin &amp; Hackett, <lb/>1990)。支持者認為同儕審查的效果至少比 <lb/>科學家的自我約束為佳，並且可提供建設性 <lb/>的理性評價以改進研究品質(Bornmann &amp; <lb/>Daniel, 2005; Nickerson, 2005)。而若就宏觀 <lb/>層面的科學發展來看，科學研究必須經過批 <lb/>判與檢驗，才得以降低錯誤，成為真正的科 <lb/>學知識(Popper, 1961; Ziman, 2000)。 <lb/>許 多 調 查 研 究 顯 示 ， 學 術 界 對 於 同 <lb/>儕審查廣泛接受且高度支持(B e r t o u t &amp; <lb/>Schneider, 2004; Boden et al., 1990; Fletcher <lb/>&amp; Fletcher, 2003; Gibson, Spong, Simonsen, <lb/>Martin, &amp; Scott, 2008; POST, 2002; Royal <lb/>Society, 1995; Ware &amp; Monkman, 2008)。 <lb/>Geisler(2000)整體論述同儕審查的優點， <lb/>包括提供稱職專家意見、減少低品質科研、 <lb/>管控科研質量、平衡不同科學觀點或思想學 <lb/>派、採取理性、有效與公平的過程、承擔科 <lb/>學發展的責任，以及協助科技資源分配與決 <lb/>策。Brown(2004)及Ware(2013)則指出 <lb/>期刊同儕審查的多項功能，例如文獻的註 <lb/>冊、保存與改進品質、學術知識的過濾與淨 <lb/>化、學術領域範圍的形塑與發展，以及評審 <lb/>者個人知識的提升等。 <lb/>不過同儕審查也招致許多批評，研究者 <lb/>綜整如下：(一)信度：評審者之間的一致性 <lb/>過低，可能存有潛在偏見；(二)公平性：評 <lb/>審過程受到非科學價值因素的影響，例如受 <lb/>評者的特殊背景或評審者的個人偏見等，而 <lb/>導致評審不公的情況；(三)效度：評審的效 <lb/>度證實不易，也缺乏客觀指標；(四)效率： <lb/>評審作業耗費時日且所費不貲；(五)創新 <lb/>性：評審結果傾向於保守主義，未能鼓勵創 <lb/>新；(六)累積性：評審方式比較有利於著名 <lb/>或資深學者，不利於缺乏學術成就的年輕科 <lb/>學家。其他的批評還包括評審過程不透明、 <lb/>評審者剽竊研究創意，以及研究內容偽造或 <lb/>抄襲等，都是經常被討論的問題(Abbott, <lb/>2008; Bornmann, 2011b; Bornmann &amp; Daniel, <lb/>2005; Braben, 2004; Chubin &amp; Hackett, 1990; <lb/>Gillet, 1993; Gluckman, 2012; Horrobin, 1990, <lb/>1996; Langfeldt &amp; Kyvik, 2011; Luukkonen, <lb/>2012; RCUK, 2007; Rip, 2000; Roy, 1985; <lb/>Travis &amp; Collins, 1991)。 <lb/></body>

			<page>52 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>總之，同儕審查是學術社群的自我規 <lb/>範機制，並已緊密地納入學術組織的運作之 <lb/>中，許多學者認為同儕審查有其先天限制，研 <lb/>究者綜整提出同儕審查的八大特質，這些都是 <lb/>在規劃同儕審查作業時必須面對的議題。 <lb/>(一) 「同儕」的定義不易：根據同儕審查 <lb/>的定義，學術領域是決定評審者的主 <lb/>要關鍵，但是學術領域的界線本有爭 <lb/>議(Price, 1963)，而且即使是相同學門 <lb/>的子領域之間，其專業性也未必可以彼 <lb/>此互通。近年來科學專業性的發展益加 <lb/>多元，愈來愈多跨領域、超學科，以及 <lb/>團隊科學的研究，使得同儕的界定更為 <lb/>困難(The British Academy, 2007; Hicks &amp; <lb/>Katz, 1996; Holbrook, 2013a, 2013b; Lamont, <lb/>2009; Langfeldt, 2001, 2006; Wood &amp; Wessely, <lb/>2003)，個別領域專家在評審跨領域研 <lb/>究時，極有可能面臨專業知識不足的問 <lb/>題(Bornmann, 2011b; Frodeman et al., 2012; <lb/>Holbrook, 2013a; Huutoniemi, Klein, Bruun, <lb/>&amp; Hukkinen, 2010; OECD, 2011a)。 <lb/>(二) 「同儕」的角色矛盾：同儕審查最顯著 <lb/>的特徵之一是評審的主客體有可能互 <lb/>換，今天擔任評審者的專家，明天可能 <lb/>在另一場合與現在的受評者直接競爭， <lb/>這種既是裁判又是球員的情況，很難避 <lb/>免利益衝突(Abdoul, Perrey, Tubach, et <lb/>al., 2012; Langfeldt, 2001)。尤其在某 <lb/>些研究者人數較少的高度專業化領域， <lb/>或者小規模科研國家，這個問題就更加 <lb/>複雜(Chubin &amp; Hackett, 1990; OECD, <lb/>2011a; Pouris, 1988)。此一潛在風險也 <lb/>促使愛爾蘭及以色列等國家，在進行學 <lb/>術相關評鑑時只邀請外國評審者參與 <lb/>(Gluckman, 2012)。 <lb/>(三) 「評審標準」的解讀彈性：以期刊同儕 <lb/>審查為例，評審者除須判斷稿件的重要 <lb/>性與合理性外，還須對整體研究提出支 <lb/>持或否決的建議，這些都是具有高度主 <lb/>觀性的議題，每個人的看法不盡相同。 <lb/>目前同儕審查的主事機構大都在事前訂 <lb/>定評審標準或原則，但是評審者在實際 <lb/>操作時，往往對於既定的標準有不同的 <lb/>解讀或權重，因而造成評審者之間一 <lb/>致性過低的現象，也引發各界對評審 <lb/>不公的質疑(Bornmann, 2011b; Chubin <lb/>&amp; Hackett, 1990, 2003; Cicchetti, 1997; <lb/>Kostoff, 2004; Rennie, 2003; Weiser, <lb/>2012; Ziman, 2000)。 <lb/>(四) 「科學品質」的求同求異：P o l a n y i <lb/>(1962)指出科學的專業標準包括信 <lb/>度、科學價值，以及原創性，前二者主 <lb/>要強調科學研究應有其一致性，但是原 <lb/>創性則是鼓勵異議與批判，此兩項特色 <lb/>在本質上就有矛盾之處。同儕審查作為 <lb/>科學研究的評審機制，自然也會面臨相 <lb/>同的難題，除了要評量出具有一致性的 <lb/>核心研究外，還要能挑選出各個領域中 <lb/>最具潛力的創新想法，此一困境由各領 <lb/>域學者對於研究前沿(research front) <lb/>的低度共識即可得證(C o l e, 2000; <lb/>Wood &amp; Wessely, 2003)。 <lb/></body>

			<page>53 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>(五) 「多重目標」的取捨與妥協：同儕審查 <lb/>作業所涉及之利益關係者眾多，主事機 <lb/>構往往訂有多重目標，但是各個目標之 <lb/>間卻經常存在彼此消長的關係。以獎助 <lb/>同儕審查為例，獎助機構的目標通常包 <lb/>括效率、效用、課責性、回應性、穩定 <lb/>性、合理性、創新性，以及公平性等， <lb/>但是若強調了課責性就必須犧牲一些創 <lb/>新性、提升穩定性將會降低回應性，而 <lb/>堅持了公平性則可能要以效用做為代價 <lb/>(Chubin, 1994; Chubin &amp; Hackett, 1990; <lb/>Luukkonen, 2012; RCUK, 2006; Wood &amp; <lb/>Wessely, 2003)。 <lb/>(六) 少數人決定的「閉門民主」：同儕審查 <lb/>經常被批評為黑箱作業，主要原因有 <lb/>二，其一、同儕審查是由少數人挑選的 <lb/>少數評審者進行審查，審查報告在本 <lb/>質上雖然只是評審者的個人意見，但 <lb/>是在實際運作時卻代表整體科學家的決 <lb/>定(Harnad, 1996; Perper, 1989; Ziman, <lb/>2000)；其二、同儕審查作業強調機密 <lb/>性，在過程不公開且不透明的情況下， <lb/>容易受到評審者個人價值觀或自身利益 <lb/>的影響，而造成評審結果不公(Chubin <lb/>&amp; Hackett, 1990; The Higher Education <lb/>Academy, 2009; Rennie, 2003)。 <lb/>(七) 「自治與責任」的挑戰：20世紀末期以 <lb/>來，各國政府要求學術領域在科學自治 <lb/>外，也要回應民眾的需求，兼顧科學研 <lb/>究的社會責任。現今全球許多國家的政 <lb/>府獎助機構已直接或間接地將社會影響 <lb/>(social impact)或國家利益納入評審 <lb/>考量，以爭取民眾對政府科研預算的支 <lb/>持。為此同儕審查的自治性與獨立性正 <lb/>在弱化，而逐漸成為一種服務國家政策 <lb/>目標的機制，這種科學認識論與政治問 <lb/>題結合的用途，更加強化了同儕審查作 <lb/>業的矛盾與兩難(Bhattacharya, 2012; <lb/>Bornmann, 2013b; Collins &amp; Tabak, 2014; <lb/>Cozzens, 1999; Frodeman et al., 2012; <lb/>Holbrook &amp; Frodeman, 2011; Holbrook <lb/>&amp; Hrotic, 2013; Kamenetzky, 2012; Rip, <lb/>2000)。 <lb/>(八) 「信賴與監督」的平衡：同儕審查的 <lb/>正當性是基於學術社群成員之間的彼 <lb/>此信賴與誠信(Abdoul, Perrey, Tubach, <lb/>et al., 2012; Giraudeau, Leyrat, Le Gouge, <lb/>Léger, &amp; Caille, 2011; Williamson, <lb/>2003)，有些學者認為Merton(1942) <lb/>的科學四大規範(普遍主義、公有主 <lb/>義、無私利性，以及有條理懷疑主義) <lb/>足以制約科學家的評審行為(Frodeman <lb/>et al., 2012; Heitman, 2002)，但是許多 <lb/>研究已經證實評審者存有各種偏見，並 <lb/>呼籲建置同儕審查的檢驗與監督機制， <lb/>以提升評審的公平性(Biagioli, 2002; <lb/>Callaham, 2003; De Vries, Marschall, <lb/>&amp; Stein, 2009; Gluckman, 2012; Levy, <lb/>1984; Smith, 2003; van Rooyen, Black, &amp; <lb/>Godlee, 1999)。 <lb/></body>

			<page>54 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>參、 同儕審查的起源與發展 <lb/>同儕審查是學術領域的核心，在期刊 <lb/>稿件出版、獎助資源分配，以及大學教職的 <lb/>聘用與升遷上都扮演著關鍵角色。不過就同 <lb/>儕審查的起源來看，除了期刊同儕審查有其 <lb/>歷史成因，可溯源自17世紀英國皇家學會出 <lb/>版的《哲學學報》(Biagioli, 2002; Kronick, <lb/>1990; Lock, 1985; Zuckerman &amp; Merton, <lb/>1971)。獎助計畫與大學教職聘用 升遷的 <lb/>同儕審查，則是在19至20世紀間，因應實 <lb/>際作業需要而獨立發展的機制，今天研究 <lb/>獎助機構及大學已廣泛採用同儕審查機制 <lb/>(Bornmann, 2011b; Weiser, 2012)。 <lb/>一、 期刊同儕審查的起源與發展 <lb/>(一) 期刊同儕審查的早期史 <lb/>1. 出版檢查與稿件品質控管 <lb/>學術界採用的同儕審查機制究竟起於何 <lb/>時，學者看法不一。Kronick(1990)認為就 <lb/>廣義來看，同儕審查遠在人類開始探索與傳 <lb/>播新知時，就已經存在，因為同儕審查(無 <lb/>論發生於出版前或出版後)是建立共識的必 <lb/>要作法，也是科學知識成長的基礎。而大部 <lb/>分的學者則將同儕審查溯源至17世紀英國皇 <lb/>家學會出版的《哲學學報》，該刊於1665年 <lb/>創刊，由學會首任秘書Henry Oldenburg擔 <lb/>任編輯，每期學報出刊前必須先由學會會 <lb/>員進行內容審查，而被視為期刊同儕審查 <lb/>的濫觴(Burnham, 1990; Kronik, 1990; Lock, <lb/>1985; Rennie, 2003; Spier, 2002a; Zuckerman <lb/>&amp; Merton, 1971)。 <lb/>Biagioli(2002)認為早期期刊同儕審 <lb/>查與政府的出版檢查制度相關，15至16世 <lb/>紀，印刷術在歐洲快速傳播，歐洲各專制政 <lb/>權為了控制言論，實施出版特許制度，規定 <lb/>任何文字內容均須經由政府核可才得以印刷 <lb/>販售。17世紀中葉，科學研究逐漸機構化， <lb/>歐洲各地由皇家支持的科學學會興起，並授 <lb/>予出版特許以推廣科學新知，此一作法等同 <lb/>將科學文獻的內容檢查工作交由科學學會負 <lb/>責。整體來看，當時科學學會的期刊同儕審 <lb/>查屬於國家出版檢查體系的一環，各學會除 <lb/>了評審稿件的科學品質外，也同時進行內 <lb/>容檢查，以排除與政府當局不一致的論點 <lb/>(Frodeman et al., 2012; Zuckerman &amp; Merton, <lb/>1971)。 <lb/>到了18世紀初期，學術期刊出版市場 <lb/>逐漸成形，一方面因為歐洲各國科學學會積 <lb/>極出版優良期刊，以建立聲望並鞏固地位； <lb/>另一方面是科學家努力發表期刊文獻，以取 <lb/>得進入科學社群的資格，因此期刊同儕審查 <lb/>的稿件品質控管功能逐漸超越了內容檢查。 <lb/>此一發展也促使期刊同儕審查在歐洲專制政 <lb/>體垮台之後，得以擺脫出版檢查幫手的負面 <lb/>形象，由政府出版檢查制度的執行者，轉身 <lb/>成為期刊稿件品質的管理者(Biagioli, 2002; <lb/>Lock, 1985)。 <lb/>然而直到19世紀未期，學術期刊並未 <lb/>立即全面採用同儕審查，主觀因素在於期刊 <lb/>編輯或出版者憂心編輯大權旁落，不願意 <lb/>借重外界專家協助審核文稿；客觀因素則是 <lb/>期刊的數量快速成長，稿件不足的情況甚為 <lb/></body>

			<page>55 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>嚴重，當時期刊編輯的首要任務是尋找好 <lb/>文章來填補版面，必要時才將稿件交由專 <lb/>家審查(Burnham, 1990; Rennie, 2003; Spier, <lb/>2002a)。 <lb/>2. 學科專門化與稿件供需逆轉 <lb/>期刊普遍採用同儕審查主要出現在20世 <lb/>紀，原因之一是期刊稿件供需情勢逆轉，隨 <lb/>著學科專門化以及科學家的人數愈來愈多， <lb/>研究文獻快速成長，使得期刊稿件不足的情 <lb/>況消失了，編輯工作的最大難題不再是尋 <lb/>找稿件來填補版面，而是如何在眾多投稿中 <lb/>挑選出最佳作品。此外在日益走向專業化的 <lb/>年代，期刊編輯必須考量評審的客觀性以及 <lb/>學者專家的需求，因此有些期刊開始以內聘 <lb/>或委外方式將稿件交由專家評審(Burnham, <lb/>1990; Rennie, 2003)。 <lb/>儘管如此，同儕審查機制並未立即成 <lb/>為顯學，各個期刊採行同儕審查的理由分 <lb/>歧、起始時間不一，評審的作業方式也多有 <lb/>差異。B u r n h a m(1990)以生醫期刊進行 <lb/>研究發現，各期刊開始實施同儕審查的年 <lb/>代沒有顯著的高峰期，身為期刊編輯或發 <lb/>行人的醫生或科學家，大都習於獨自面對 <lb/>專業學門上的變遷或挑戰，也很少參考或 <lb/>直接援引其他期刊編輯的作法。直到二次 <lb/>大戰後期，愈來愈多期刊編輯將稿件交由 <lb/>專家評審，期刊市場採用同儕審查機制的 <lb/>趨勢已然成形，不過同儕審查仍然沒有標 <lb/>準程序，而且各個期刊有不同的作業方式 <lb/>(Manske, 1997)。 <lb/>(二) 期刊同儕審查的當代發展 <lb/>當代期刊同儕審查普及化的另一股助 <lb/>力來自於書目計量(bibliometrics)，20世 <lb/>紀中葉，Garfield利用引文分析提出期刊影 <lb/>響係數(impact factor)(Garfield &amp; Sher, <lb/>1963)，使得期刊同儕審查的效度具象化， <lb/>同儕審查不再只是為期刊文獻的品質背書， <lb/>也具有期刊品牌保證的功用。許多期刊資料 <lb/>庫亦將同儕審查列為期刊收錄的必備條件之 <lb/>一(OECD, 2011a)，間接地促進期刊同儕 <lb/>審查的發展。 <lb/>到了20世紀後期，書目計量的各項指 <lb/>標，尤其是引文分析，又以其客觀、公平及 <lb/>簡易的優勢，逐漸成為評鑑個人或機構研究 <lb/>表現的重要參考，促使學者積極在同儕審查 <lb/>期刊發表文獻，除了累積個人學術成就外， <lb/>並可提升獲得研究獎助或擔任大學教職的機 <lb/>會。因此期刊同儕審查再次經由書目計量的 <lb/>連接，間接成為影響獎助計畫申請及大學教 <lb/>職聘用與升遷的重要因素(Harley &amp; Acord, <lb/>2011; Harley et al., 2010; van Arensbergen, van <lb/>der Weijden, &amp; van den Besselaar, 2014a)。 <lb/>另外對於身處資訊爆炸時代的期刊讀者來 <lb/>說，期刊同儕審查的文獻品管功能，也是值 <lb/>得信賴的閱讀保證。根據英國非政府組織 <lb/>Sense about Science(2010)針對期刊文獻作 <lb/>者及評審者進行的全球性調查發現，84%的 <lb/>受調者認為若無期刊同儕審查機制，學術傳 <lb/>播將失去控制。 <lb/>經過300多年的發展，期刊同儕審查已 <lb/>成為科學知識的守門者，受到學術社群的重 <lb/></body>

			<page>56 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>視，但是也有批評與改革的聲浪。近年來網 <lb/>路科技的發展使得期刊同儕審查出現許多創 <lb/>新作法，例如預印同儕審查的arXiv典藏庫及 <lb/>出版後同儕審查的PLoS電子期刊，都是相當 <lb/>成功的例子；後者除可讓讀者留言評論外， <lb/>每篇文獻亦提供閱讀、引用及下載次數等最 <lb/>新統計。但是這些成功並不代表傳統期刊同 <lb/>儕審查即將消失，尤其在各國政府與學術界 <lb/>對書目計量益加重視的情況下，學者仍然必 <lb/>須努力在同儕審查期刊發表研究成果，以提 <lb/>升個人的學術成就與聲望(Harley &amp; Acord, <lb/>2011; Rennie, 2003)。 <lb/>今天期刊同儕審查所面對的是一個快 <lb/>速轉換的年代，電子期刊出版的發展及品質 <lb/>持續改進，加上人類閱讀習慣的改變，許多 <lb/>學者認為期刊同儕審查在不久的將來可能發 <lb/>生革命性的變化。Smith(2003, 2009)認為 <lb/>期刊同儕審查的缺點大於優點，在過去數百 <lb/>年之所以停滯不前，主要是缺乏競爭者，他 <lb/>相信未來的同儕審查作業將會更加公開與透 <lb/>明，而企業界的作業流程再造及持續改進等 <lb/>管理作法，可能全面提升同儕審查的效率、 <lb/>效用與公平性。 <lb/>二、 獎助同儕審查的起源與發展 <lb/>(一) 獎助同儕審查的起源─以英美兩國為例 <lb/>除了學術期刊外，研究計畫獎助機構 <lb/>是最廣泛採用同儕審查的單位(Bornmann, <lb/>2011b)。19世紀以來，英美等國陸續出現 <lb/>支持科學研究的機構，當時即經常由科學家 <lb/>組成的委員會協助分配獎項，例如1831年成 <lb/>立的英國科學促進會(British Association for <lb/>the Advancement of Science)，下設各種不 <lb/>同領域的專業委員會，負責評審各類研究申 <lb/>請案件。美國華府卡內基研究所(Carnegie <lb/>Institution of Washington)亦於1902年設置 <lb/>了18個主題諮詢委員會，評審並推薦獎助申 <lb/>請案件；而美國國家研究委員會(National <lb/>Research Council)在1919年就利用同儕審 <lb/>查機制決定獎學金人選(Burnham, Sauer, &amp; <lb/>Gibbs, 1987)。 <lb/>基本上獎助同儕審查的發展與政府職 <lb/>能擴張息息相關，當各國政府開始承擔支持 <lb/>科學研究的責任，同儕審查就逐漸成為政 <lb/>府獎助經費的主要分配工具(Frodeman et <lb/>al., 2012)。以英國為例，第一次大戰後期 <lb/>Richard Haldane(1856-1928)授命檢討政府 <lb/>效能，所提建議之一是將政府資助的科研計 <lb/>畫分為指定及非指定研究兩類；前者由政府 <lb/>主導獎助決策，後者則設置獨立的科學研究 <lb/>委員會，讓科學家共同決定研究的優先順序 <lb/>與經費分配，以強化科學發展的自主性，並 <lb/>避免來自政治人物或行政部門的干預，這就 <lb/>是著名的霍爾丹原則(Haldane Principle)。 <lb/>兩年之後(1920年)英國醫學研究委員會 <lb/>(Medical Research Council)成立，採用同 <lb/>儕審查方式分配醫學類非指定研究獎助經 <lb/>費(Boden et al., 1990; RCUK, 2006; RIN, <lb/>2010)。目前英國有七個不同領域的研究委 <lb/>員會，都是依據皇家憲章設置的準政府機 <lb/>構，由政府科技主管部門訂定各個委員會的 <lb/>經費預算與政策目標，並考核其運作績效。 <lb/></body>

			<page>57 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>根據英國醫學研究慈善協會(Association of <lb/>Medical Research Charities)統計，英國各種 <lb/>公共基金每年發放出去的醫學研究獎助經費 <lb/>有20多億英磅，其中超過95%是透過同儕審 <lb/>查機制進行分配(Ismail et al., 2009)。 <lb/>美國獎助同儕審查的發展主要在二次 <lb/>大戰之後，政府開始編列巨額預算獎助科學 <lb/>研究。與英國的發展相較，美國的獎助同 <lb/>儕審查在一開始就有兩種不同作法，一為 <lb/>法制化模式，另一為強勢計畫管理者模式 <lb/>(Chubin &amp; Hackett, 1990; Guston, 2003)； <lb/>前者以美國國家衛生院(National Institutes <lb/>of Health, NIH)為代表，聯邦政府以法令 <lb/>規定NIH及其所屬機構必須採用同儕審查機 <lb/>制；後者主要起源於美國海軍研究署(U S <lb/>Office of Naval Research, ONR)，該署在 <lb/>1940年代末期開始設立科學研究獎助基金， <lb/>讓獎助計畫管理者擁有最後決定實權，而同 <lb/>儕審查機制則非必要選項(Burnham et al., <lb/>1987; Frodeman et al., 2012)。1950年美國國 <lb/>家科學基金會(National Science Foundation, <lb/>N S F)成立，仿效O N R的強勢計畫管理者 <lb/>模式，但是也私下納入NIH的同儕審查作法 <lb/>(England, 1982; Frodeman et al., 2012)。 <lb/>20世紀後期，美國政府強調施政績效管 <lb/>理，美國科技政策辦公室(Office of Science <lb/>and Technology Policy)為了促進聯邦獎助 <lb/>機構採用同儕審查機制，自1996年起聯合 <lb/>管理與預算辦公室(Office of Management <lb/>a n d B u d g e t)共同提出年度指導綱領，要 <lb/>求各聯邦獎助機構增加同儕審查評選之獎 <lb/>助比例(General Accounting Office [GAO], <lb/>1999)。到了2000年，美國聯邦R&amp;D預算 <lb/>中共有260億美元(31.4%)係以同儕審查機 <lb/>制進行分配(Guston, 2003)。另外美國政 <lb/>府獎助機構也受到較多政治團體的影響，美 <lb/>國國會主張的學術指定撥款(earmark)即 <lb/>為一例(Savage, 1999; Scarpa, 2009)；有些 <lb/>國會議員認為由科學家主導的獎助同儕審查 <lb/>存有地理偏見，要求直接依據地理區域分配 <lb/>獎助經費。根據美國科學促進會(American <lb/>Association for the Advancement of Science, <lb/>AAAS)統計，2010年美國國會R&amp;D學術指 <lb/>定撥款約42.7億美元，占R&amp;D總費用的2.8% <lb/>(American Association for the Advancement <lb/>of Science, 2010)。 <lb/>(二) 獎助同儕審查的當前重要議題 <lb/>同儕審查原本是學術界的一種封閉、 <lb/>自成體系的評審過程，科學家利用這個機 <lb/>制將學術研究品質的控管權力限縮在科學 <lb/>家族之內，形成所謂的科學自治。1980年 <lb/>代，英美等國面對龐大的預算赤字，開始 <lb/>檢討政府獎勵科學研究的成效與課責性，要 <lb/>求政府獎助機構的經費運用除了考量科學發 <lb/>展外，還須提出有益社會的證據，為此社會 <lb/>影響指標逐漸成為各國獎助同儕審查的重 <lb/>要評審項目之一(Cozzens, 2001; Frodeman <lb/>&amp; Briggle, 2012; Hackett, 1997; Kamenetzky, <lb/>2012; Martin, 2011; OECD, 2011a; Roberts, <lb/>2009)。 <lb/>美國NSF是較早納入社會影響指標的機 <lb/>構之一，1997年NSF將原來的四項評審標準 <lb/></body>

			<page>58 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>簡化為智識價值(intellectual merit)與更廣 <lb/>泛影響(broader impact)兩項(Holbrook, <lb/>2012; Mervis, 2011)；而歐盟第5架構計畫 <lb/>(1998-2002)所採用的5項評審指標中，有 <lb/>3項與社會影響相關(Holbrook &amp; Frodeman, <lb/>2011)。除了前兩者外，Holbrook(2010) <lb/>認為美國N I H及N a t i o n a l O c e a n i c a n d <lb/>Atmospheric Administration、加拿大Natural <lb/>Sciences and Engineering Research Council， <lb/>以及荷蘭Technology Foundation也都有類 <lb/>似的做法；而最近啟動的歐盟第8架構計畫 <lb/>(Horizon 2020)，影響力(impact)仍然是 <lb/>重要審查項目之一。 <lb/>除了社會影響指標，創新性亦是近年 <lb/>來獎助同儕審查的重要議題。許多文獻指 <lb/>出同儕審查具有保守傾向，不利創新計畫 <lb/>評選(Braben, 2004, 2011; Chubin &amp; Hackett, <lb/>1990; Gillett, 1993; Horrobin, 1990, 1996; <lb/>Langfeldt, 2006; Langfeldt &amp; Kyvik, 2011; <lb/>Luukkonen, 2012; OECD, 2011a; Roy, 1985; <lb/>Yalow, 1982; Ziman, 2000)。為了改進此一 <lb/>現象，有些獎助機構調整同儕審查的運作方 <lb/>式，例如要求獎助申請者詳列研究的創新 <lb/>性、聘請非專業人士進入評審團隊，以及強 <lb/>化計畫管理者的決策權限等；有些獎助機構 <lb/>則創設特定獎助項目，例如指定研究主題獎 <lb/>項、創意科學家個人獎項、跨領域或團隊科 <lb/>學研究獎項等，以鼓勵創新研究(Frodeman <lb/>&amp; Holbrook, 2012; Guthrie, Guérin, Wu, Ismail, <lb/>&amp; Wooding, 2013; Ismail et al., 2009; Spier, <lb/>2002b)。 <lb/>然而無論是評審社會影響或創新性， <lb/>都必須面對評審者選聘及評審標準訂定兩 <lb/>項難題(Bell, Shaw, &amp; Boaz, 2011; van der <lb/>Meulen &amp; Rip, 2000)。學術界除了對於兩項 <lb/>指標的評審者選聘缺乏共識外，反對社會影 <lb/>響指標的學者認為，考量社會需要可能對科 <lb/>學自治形成干擾，而且社會影響的效用非可 <lb/>立竿見影，也難以推論因果(Bhattacharya, <lb/>2012; Bornmann, 2012; Bornmann &amp; Marx, <lb/>2014; Bozeman &amp; Boardman, 2009; Holbrook <lb/>&amp; Frodeman, 2011; Martin, 2011; Rymer, 2011; <lb/>van der Meulen &amp; Rip, 2000)；而批評創新 <lb/>性指標的學者則表示，所謂創新計畫的定義 <lb/>不夠明確，評審標準各異，而且缺乏可靠的 <lb/>效用考評機制(Donovan, 2011; Frodeman &amp; <lb/>Holbrook, 2012; Lal &amp; Peña, 2013)。 <lb/>三、 大學教職聘用 升遷同儕審查的起源與 <lb/>發展 <lb/>(一) 大學教職聘用 升遷的制度化─以美國 <lb/>為例 <lb/>對於學術界人士來說，大學教職聘用 <lb/>升遷同儕審查是個神祕又令人敬畏的作業， <lb/>除了評審過程強調機密性外，未能獲得終身 <lb/>教職的老師極可能面臨失業的困境(Weiser, <lb/>2012)。相較於期刊稿件及獎助計畫評審， <lb/>美國大學教職聘用 升遷同儕審查的發展較 <lb/>遲，主要以學術界的同儕審查為根本，並奠 <lb/>基於1940年以來逐漸成熟的大學教職職級 <lb/>(academic ranks)與終身教職(tenure)制 <lb/>度(Weiser, 2012)。 <lb/></body>

			<page>59 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>早期美國大學教職聘用與升遷的權力 <lb/>大多集中在學校行政部門，教職工作缺乏 <lb/>保障，甚至可能因為學校捐款人或董事會 <lb/>成員向校方施壓而失去工作，直到大學實 <lb/>施終身教職制度才改變此一情況(B r o w n <lb/>&amp; Kurland, 1990; Cameron, 2010; Metzger, <lb/>1990; Weiser, 2012)。1915年美國大學教 <lb/>授協會(American Association of University <lb/>Professors, AAUP)成立，除鼓吹學術自 <lb/>由外，也提出教職解雇作業準則，以及倡 <lb/>議終身教職制度(American Association of <lb/>University Professors [AAUP], 1915)。之後 <lb/>AAUP在1940年提出學術自由與終身教職聲 <lb/>明，除詳列由試用到終身教職的進程外，並 <lb/>強調終身教職制度是學術自由的基礎，讓教 <lb/>師擁有研究出版、課堂講授與討論，以及言 <lb/>論發表與寫作的自主空間。但是該聲明並未 <lb/>提及教職聘用與終身教職的評審標準，比較 <lb/>相關的文句是：學術自由的目標是教學與研 <lb/>究(AAUP, 1940; Weiser, 2012)。 <lb/>經過AAUP多年的努力，目前美國大學 <lb/>普遍採用終身教職制度，教職工作獲得制度 <lb/>性的保障。不過每所學校之教職聘用 升聘 <lb/>同儕審查的作業方式差異甚大，甚至在同一 <lb/>所大學內的不同系所也可能有別，以評審者 <lb/>為例，有的以內部評審為主、有的強調外部 <lb/>評審，有的則是內外部評審兼具(Frodeman <lb/>et al., 2012; Gross-Schaefer, Gala, Jaccard, &amp; <lb/>Vetter, 2015; Weiser, 2012)。1966年，AAUP <lb/>提出大學院校治理聲明，呼籲由大學校務董 <lb/>事成員、行政管理者、教職員、學生及其 <lb/>他成員等共同承擔學校治理的責任(AAUP, <lb/>1966)。這股大學共同治理風潮，不但擴增 <lb/>了大學教職聘用 升遷同儕審查作業所涉及 <lb/>之利益關係者，也使得評審的決策權力結 <lb/>構更加複雜多元(Cummings &amp; Finkelstein, <lb/>2012; Weiser, 2012)。 <lb/>(二) 大學教職聘用 升遷同儕審查的重要議題 <lb/>整體來看，大學教職聘用 升遷同儕 <lb/>審查的評審標準係以教學、研究與服務為 <lb/>主，但是自20世紀後期以來，許多國家的 <lb/>大學都出現偏重研究的情況(Fairweather, <lb/>2005; Greenbank, 2006; Kreber, 2002; Pratt, <lb/>1997)，原因之一為各國政府高教機構評 <lb/>鑑大多強調書目計量指標；之二是各國政 <lb/>府的高教經費縮減，校務營運益形倚重校 <lb/>外研究獎助資源(Andersen, 2003; Becher &amp; <lb/>Trowler, 2001; Bornmann, 2013a; Greenbank, <lb/>2006; Harley et al., 2010; Waters, 2009)。在 <lb/>這種雙重的壓力下，學者出版期刊文獻及獲 <lb/>得研究獎助之能力，就成為爭取大學教職聘 <lb/>用與升遷的關鍵因素(van Arensbergen et al., <lb/>2014a; van Arensbergen, van der Weijden, &amp; <lb/>van den Besselaar, 2014b)。批評者認為此一 <lb/>趨勢形同將大學教職聘用 升遷同儕審查的 <lb/>工作，委由期刊出版商及研究獎助機構辦理 <lb/>(Boyer, 1997; Harley &amp; Acord, 2011; Harley <lb/>et al., 2010)。 <lb/>除了偏重研究外，許多國家的大學教 <lb/>職聘用 升遷同儕審查也有忽視教學表現的 <lb/>情況。英國的大學教師多意識到各級政府及 <lb/>學校比較重視研究成績(Dearing, 1997)， <lb/></body>

			<page>60 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>並認為教學表現與教職升等之間的關聯性不 <lb/>大(Young, 2006)；澳洲的調查也有類似的 <lb/>發現，儘管大多數的學者(88.2%)支持獎 <lb/>勵優質教學，但是只有31.4%的教師認為教 <lb/>學表現有助升遷(Bexley, James, &amp; Arkoudis, <lb/>2011)。另外Milem、Berger與Dey(2000)指 <lb/>出在1972至1992年間，美國四年制大學教師 <lb/>從事研究工作的時數顯有增加，但是在課外 <lb/>與學生進行諮商或互動的機會卻相對減少。 <lb/>近年來，許多國家已經注意到大學校 <lb/>園存在重視研究而輕忽教學的情況，積極調 <lb/>整高等教育管理政策並鼓勵優質教學，以促 <lb/>進研究與教學的平衡。2010年OECD出版高 <lb/>等教育優質教學回顧報告，調查分析全球20 <lb/>國、29家高等教育機構的46項優質教學計畫 <lb/>方案，提供全球各大學參考。該報告並指出 <lb/>各國高等教育機構評鑑以及世界大學排名大 <lb/>多過度重視研究指標，而引發輕忽教學的批 <lb/>評，不過如何評鑑教學品質，也是學術界必 <lb/>須積極面對的議題(Hénard, 2010)。 <lb/>肆、 同儕審查的研究現況 <lb/>同儕審查是學術界有限資源的分配機 <lb/>制，其操作過程卻具機密性，在公眾領域幾 <lb/>乎沒有任何線索，直到1980年代前後才開始 <lb/>有較多理性檢驗(Chubin &amp; Hackett, 1990; <lb/>Rennie, 2003; Weller, 2002)。目前同儕審查 <lb/>的研究以期刊稿件及獎助計畫為主，大學教 <lb/>職聘用與升遷的探討甚少；不過許多學者 <lb/>指出大多數文獻的方法論不夠嚴謹、因果 <lb/>推論較為薄弱，而且各篇研究結果的異質 <lb/>性甚大，難以通則化，建議採用後設分析 <lb/>法或實驗研究加以補強(Bornmann, 2011b; <lb/>Bornmann, Nast, &amp; Daniel, 2008; De Vries et <lb/>al., 2009; Demicheli &amp; Di Pietrantonj, 2007; <lb/>Jefferson et al., 2007)，Marsh、Jayasinghe與 <lb/>Bond(2011)則認為除了二手文獻的後設分 <lb/>析外，大規模一手評審資料的研究亦有其必 <lb/>要性。 <lb/>一、 打開同儕審查的「黑盒子」 <lb/>期刊同儕審查的理性檢驗在1980年代 <lb/>逐漸受到重視，Rennie(2003)舉出兩項具 <lb/>體事證，其一為1985年The British Medical <lb/>Journal(BMJ)總編輯Stephen Lock在英國 <lb/>奈菲爾基金會(Nuffield Foundation)的支 <lb/>持下出版第一本期刊同儕審查專書─《困難 <lb/>的平衡》(A Difficult Balance)，內容分析 <lb/>期刊同儕審查的作業細節，並呼籲進行更多 <lb/>的討論與研究；其二是1989年首屆同儕審查 <lb/>與生醫期刊研討會在美國芝加哥舉行，之後 <lb/>每四年辦理一次，除了論文發表數量逐屆成 <lb/>長外，研究的品質與複雜度也見提升。在這 <lb/>股研究風潮的影響下，加上期刊市場競爭日 <lb/>烈，許多期刊編輯開始進行同儕審查作業的 <lb/>自我檢驗；而透過愈來愈多的研究，期刊編 <lb/>輯也益加無法專斷決定稿件的命運(Altman, <lb/>1996; Rennie, 1998a, 1998b, 2003; Smith &amp; <lb/>Rennie, 1995)。 <lb/>獎助同儕審查的早期研究亦多屬自我 <lb/>檢驗類型，以美國為例，NIH及NSF在1970 <lb/>至1980年代即曾分別委託學者進行同儕審 <lb/></body>

			<page>61 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>查作業的自我檢驗(Burnham et al., 1987; <lb/>Chubin &amp; Hackett, 1990)。Chubin與Hackett <lb/>(1990)將獎助同儕審查的研究分為三類並 <lb/>說明其特色，其一、獎助機構委託學者之研 <lb/>究：獎助機構指定學者並提供研究資料，因 <lb/>為學者類似自己人，研究結論大多偏向機構 <lb/>立場；其二、獎助機構贊助學者之研究：學 <lb/>者雖然擁有較多探索及表達的自主空間，但 <lb/>是研究資料仍需仰賴獎助機構提供，增加了 <lb/>研究的複雜性，研究結論也比較容易失真； <lb/>其三、學者自發性地獨立研究：學者不但沒 <lb/>有獲得任何經費與社會支援，而且必須自行 <lb/>設法接近研究目標群體。直到20世紀末期， <lb/>許多國家的公共獎助機構在政府資訊開放及 <lb/>政策目標管考的壓力下，為了提升同儕審查 <lb/>的作業品質與效能，比較願意將第一手評審 <lb/>檔案提供學者進行研究，有些甚至允許學者 <lb/>訪談評審者或觀察評審委員會的議事與決策 <lb/>過程(Bornmann &amp; Daniel, 2005; Lamont, 2009; <lb/>Langfeldt, 2001; Marsh, Jayasinghe, &amp; Bond, <lb/>2008; Wood &amp; Wessely, 2003)，使得獎助同儕 <lb/>審查的評審作業逐步邁向開放與透明之途。 <lb/>相較於期刊及獎助同儕審查，大學教職 <lb/>聘用 升遷同儕審查的作業程序更為複雜， <lb/>除了利益關係者眾多及評審權力結構多元外 <lb/>(Cummings &amp; Finkelstein, 2012)，評審過 <lb/>程亦具機密性，相關研究一向不多(Brooks, <lb/>1988; Weiser, 2012)。但是到了1990年代前 <lb/>後，許多國家的教育經費縮減及學生人數 <lb/>減少，大學教職的穩定性受到影響，此項強 <lb/>調學者個人表現的審查作業開始受到重視， <lb/>有關評審標準的討論也日漸增加(Becher &amp; <lb/>Trowler, 2001; Harley &amp; Acord, 2011; Harley et <lb/>al., 2010; Weinbach &amp; Randolph, 1984)，不 <lb/>過大學教職聘用 升遷同儕審查，迄今依然 <lb/>處在密閉的黑盒子之中。 <lb/>二、 同儕審查的研究現況 <lb/>(一) 期刊同儕審查的研究現況 <lb/>Chubin與Hackett(1990)將期刊同儕 <lb/>審查研究分為兩類，一者針對評審作業程 <lb/>序，探討稿件審查的準確性或評審意見的信 <lb/>度與效度等；一者視同儕審查為科學研究的 <lb/>守門者，強調評審的公平性，譴責各種類型 <lb/>的偏見。許多學者指出期刊同儕審查文獻的 <lb/>研究設計差異甚大，有針對編輯、評審者或 <lb/>作者進行調查；有探討評審結果與可能變項 <lb/>(評審者或編輯背景等)之相關性；有以編 <lb/>輯或評審者的審查報告進行內容分析或個案 <lb/>研究，不過各篇文獻大都只著重於同儕審查 <lb/>的某個面向，在研究方法上也各有其優點與 <lb/>不足(Bornmann, 2011b; Chubin &amp; Hackett, <lb/>1990; De Vries et al., 2009; Jefferson et al., <lb/>2007)。Weller(2002)亦發現同儕審查的 <lb/>研究雖然橫跨各個領域，但是主要集中在醫 <lb/>學、社會科學及心理學，而且各學科的研究 <lb/>重點並不相同，例如醫學領域對於統計方法 <lb/>的評審方式甚為關切、心理學與社會學則強 <lb/>調評審者的偏見，而有關拒絕率的研究通常 <lb/>來自於社會科學領域。 <lb/>Bornmann(2011b)的回顧文獻指出， <lb/>最近十餘年的期刊同儕審查實徵研究以信度 <lb/></body>

			<page>62 <lb/></page>

			<note place="headnote">第1期 (2016.6) <lb/></note>

			<body>及公平性為主，許多研究發現評審者之間的 <lb/>信度不高，但是評審者對於拒絕稿件的共識 <lb/>程度高於接受稿件；至於公平性問題雖經有 <lb/>些文獻證實，然而因為研究結果不一，難以 <lb/>通則化。另有少數文獻針對同儕審查的預期 <lb/>效度進行檢驗，探討是否評選出最佳稿件， <lb/>有些作者發現稿件遭到拒絕之後，另在其他 <lb/>期刊登載的比例甚高，而且不必然是知名度 <lb/>較差的期刊，似乎顯示稿件審查除了基於 <lb/>科學品質外，也受到審查過程所在情境的影 <lb/>響；也有學者利用引用數據作為效度指標， <lb/>比較接受稿件與拒絕稿件之影響力，大都顯 <lb/>現編輯的決定具有高預期效度，還有研究證 <lb/>實接受稿件的被引用情形也高於拒絕稿件 <lb/>(Bornmann, 2010)。 <lb/>期刊同儕審查迄今只有少數準實驗或實 <lb/>驗研究，Peters與Ceci(1982)將美國12家著 <lb/>名期刊2至3年前出版的文獻各選1篇(共12 <lb/>篇)，經變造作者姓名及服務機構後再投稿 <lb/>原出版期刊，結果只有3篇被識破，另外9篇 <lb/>反而成了拒絕稿件。此篇文獻的研究設計雖 <lb/>然遭到學術道德的批評，但是卻被後續研究 <lb/>者廣泛引用，做為批評期刊同儕審查的重要 <lb/>佐證。另外有些期刊主動進行實驗研究，例 <lb/>如評審者的偵錯能力分析(Baxt, Waeckerle, <lb/>&amp; 1998)，以及雙盲或簽 <lb/>升同儕審查的作業品質與公平性(Godlee, <lb/>&amp; Martyn, 1998; Justice et al., 1998; <lb/>McNutt, Evans, Fletcher, &amp; Fletcher, 1990; <lb/>Nylenna, Riis, &amp; Karlsson, 1994; van Rooyen, <lb/>Godlee, Evans, Smith, &amp; Black, 1998)。 <lb/>近年來期刊同儕審查的發展受到網路及 <lb/>電子出版的衝擊，有些期刊出版者或研究機 <lb/>構主動嘗試新型態評審作法，例如預印、出 <lb/>版後或公開同儕審查等，辦理的成效不一， <lb/>有的持續至今，有的半途中止(Bornmann, <lb/>2011b; Harnad, 2000; Nature, 2006; RIN, <lb/>時代最適當的期刊稿件評審模式(Borgman, <lb/>Bornmann &amp; Daniel, 2010; Bornmann, <lb/>Schier, Thor, &amp; Daniel, 2010; Ford, <lb/>2013; Odlyzko, 1996; van Rooyen, Delamothe, <lb/>&amp; Evans, 2010)。 <lb/>(二) 獎助同儕審查的研究現況 <lb/>公平性與信度是獎助同儕審查長期受到 <lb/>關注的議題，預期效度的研究則較少，重要 <lb/>學者在探討公平性時，係將多階段的獎助同 <lb/>儕審查視為一個整體，僅由評審結果分析可 <lb/>能的偏見。此類研究的主要問題在於因果推 <lb/>論薄弱，而且各篇文獻的結論異質性甚大， <lb/>難以通則化(Bornmann, 2011b; Demicheli &amp; <lb/>Di Pietrantonj, 2007)；(2)信度：獎助同儕 <lb/>審查評審者之間的信度過低是普遍存在的現 <lb/>象(Cicchetti, 1991; Goldman, 1994; Hodgson, <lb/>1997; Oxman et al., 1991)，有些學者認為 <lb/>低信度來自於評審者的個人偏見(Eckberg, <lb/>Kostoff, 1995; Opthof &amp; Wilde, 2009; <lb/></body>

			<page>63 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>Wessely, 1998)；有些學者卻認為評審者的 <lb/>看法不一致，符合科學評審的常態(Chubin <lb/>&amp; Hackett, 2003; Cole, 1992; Stricker, 1991; <lb/>&amp; Wessely, 2003)；(3)預期效度：少 <lb/>數文獻利用獲獎及落選計畫的引用數據，探 <lb/>討評審的預期效度，各篇研究結果的反差甚 <lb/>大，沒有系統性結論；不過此類研究有其 <lb/>先天困難，因為落選的獎助計畫大多胎死 <lb/>腹中，難以追蹤其效度(Bornmann, 2011a; <lb/>Langfeldt, 2006; Mutz, Bornmann, &amp; Daniel, <lb/>2015)。 <lb/>近年來獎助同儕審查研究有了大幅進 <lb/>展，愈來愈多政府獎助機構願意開放評審 <lb/>過程資訊提供研究，學者不再只是針對評 <lb/>審結果進行分析，並可探討各階段的審查 <lb/>作業細節(Bornmann, Leydesdorff, &amp; van <lb/>den Besselaar, 2010)，有學者觀察獎助評 <lb/>審委員會的議事運作及決策過程(Lamont, <lb/>2009; Langfeldt, 2001, 2006; Luukkonen, 2012; <lb/>Olbrecht &amp; Bornmann, 2010)；有學者分 <lb/>析內外部評審者的審查報告及決審會議紀 <lb/>錄(Abdoul, Perrey, Amiel, et al., 2012)； <lb/>亦有學者探討不同評審階段的評審者所使 <lb/>用 的 評 審 標 準 以 及 各 階 段 評 審 結 果 的 <lb/>穩定性與相關性等(Bornmann &amp; Daniel, <lb/>Bornmann, Mutz, &amp; Daniel, 2008; van <lb/>Arensbergen et al., 2014a; van den Besselaar <lb/>&amp; Leydesdorff, 2009)。目前大部分研究指 <lb/>出，獎助同儕審查的內、外部評審者或評審 <lb/>委員會成員，大多依據獎助機構所預訂的評 <lb/>標準的看法或重視程度有別，是否因而影 <lb/>響評審結果，仍有待進一步討論(Abdoul, <lb/>Perrey, Amiel, et al., 2012; Bornmann &amp; Daniel, <lb/>2005; Langfeldt, 2001)。 <lb/>獎助機構也進行少數實驗性研究，最 <lb/>著名者為美國NSF的評審者一致性實驗，研 <lb/>究團隊推論有一半的獲獎者是受到隨機因素 <lb/>的影響(Cole, Cole, &amp; Simon, 1981)。近年 <lb/>來European Molecular Biology Organization <lb/>性申請者的結論(Ledin, Bornmann, Gannon, <lb/>&amp; Wa l l o n, 2007)；另有澳洲研究委員會 <lb/>(Australian Research Council)以少數專家 <lb/>信度提升外，在評審時間與經費上亦較為經 <lb/>濟(Jayasinghe, Marsh, &amp; Bond, 2006)。 <lb/>(三) 大學教職聘用 升遷同儕審查的研究現況 <lb/>升遷同儕審查的研究 <lb/>序，以及評審決策權力結構等議題。美國當 <lb/>代語言協會(Modern Language Association, <lb/>MLA)於2005年進行的教職升遷調查指出， <lb/>美國四年制英語及外語系所在評審終身教 <lb/>職時，認為出版品非常重要者達75.7%， <lb/>比Wilcox(1970)在40多年(1966-1967) <lb/>前的調查高出兩倍強(35.4%)；該調查 <lb/>重視，甚至有不予承認的情況(M o d e r n <lb/>Language 2006)。另有一些文 <lb/>獻證實研究計畫獲獎紀錄也是大學教職聘 <lb/>用 <lb/></body>

			<page>64 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>會Independent Research的獲獎者成為正教 <lb/>授的比率為16%，落選者則只有9%(Bloch, <lb/>Graversen, &amp; Pedersen, 2014)。歐盟研究 <lb/>委員會(European Research Council)的 <lb/>Starting Grants及德國研究協會(Deutsche <lb/>DFG)的Emmy <lb/>Noether Programme的獲獎者，也有類似的情 <lb/>形(Hornbostel, Böhmer, Klingsporn, Neufeld, <lb/>&amp; von Ins, 2009; Laudel Glaser, 2012)。 <lb/>關於大學教職聘用 升遷同儕審查的 <lb/>評審作業程序，Weiser(2012)蒐集美國多 <lb/>所大學的運作方式，綜整提出五大共通點， <lb/>包括評審項目(新聘或教職職級)、評審 <lb/>者(內部評審或外部評審)、評審者的評 <lb/>審範圍、評審標準，以及評審作業的機密 <lb/>性。他並指出內部評審一般分為系級、院 <lb/>級及校級，各級評審委員會的組成及標準都 <lb/>不相同，至於外部評審則以研究型大學較 <lb/>為普遍。另外有關評審決策權力結構的研 <lb/>究，根據德國Kassel大學International Center <lb/>for Higher Education Research進行之跨國調 <lb/>查發現，大學教職的研究、教學與服務評鑑 <lb/>利益團體、校級行政部門、系主任與院長、 <lb/>教師委員會或協會、同事，以及學生等六 <lb/>大類，而且各利益關係者對於教師評鑑結 <lb/>果的影響力也隨著國家與機構而有所不同 <lb/>(Cummings &amp; Finkelstein, 2012)。 <lb/>近年來，許多學者批評大學教職聘用 <lb/>升遷同儕審查存在偏重研究的現象，並且過 <lb/>度重視學者之期刊文獻出版及研究計畫獲 <lb/>獎的能力(Andersen, 2003; Harley &amp; <lb/>Harley et al., 2010)。為了促進學術 <lb/>領域有關個人表現評審的公平性，歐盟第 <lb/>7架構支持的跨國合作研究計畫A C U M E N <lb/>(Academic Careers Understood through <lb/>Measurements and Norms)，整合了同儕 <lb/>審查、書目計量及網路計量3種評審方式， <lb/>提出個人學術表現評審架構─A C U M E N <lb/>P o r t f o l i o，並出版詳細操作綱領，以供獎 <lb/>助計畫或大學教職聘用 升遷等主事機構 <lb/>參考運用。ACUMEN架構的第一部份是受 <lb/>narrative)，第二部 <lb/>分為專業(expertise)、產出(output)， <lb/>以 及 影 響 ( i n f l u e n c e ) 等 三 項 次 架 構 <lb/>(ACUMEN Consortium, 2014; Tatum &amp; <lb/>Wouters, 2013)。 <lb/>伍、 同儕審查的展望 <lb/>近半個世紀以來，除了學術界對於同 <lb/>儕審查研究的廣度與深度逐漸提升外，同儕 <lb/>審查的主事機構亦積極進行國際合作，出版 <lb/>評審作業的基本規範或操作指南，以強化審 <lb/>查的品質與公信力。在此同時，書目計量也 <lb/>憑藉著客觀與簡易的特質逐漸受到各界的重 <lb/>視，近年來更與同儕審查並列為學術評鑑的 <lb/>兩大主要工具。有些學者認為同儕審查與書 <lb/>目計量各有其優缺點，而且具有彼此互補功 <lb/>能，若能整合運用，應可提升學術評審作業 <lb/>的品質與效用。 <lb/></body>

			<page>65 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>一、 <lb/>同儕審查的作業方式在大多數的國家 <lb/>定，或有明訂操作指南，或有依內部慣例進 <lb/>行，各個機構的作法甚為多元(Bornmann, <lb/>2011b; GAO, 1999; OECD, 2011a; Rennie, <lb/>Weiser, 2012; Weller, 2002; Wood &amp; <lb/>Wessely, 2003)。不過多年來各國同儕審查 <lb/>主事機構亦積極進行國際交流，彼此分享經 <lb/>驗，以提升同儕審查的品質與公信力。目前 <lb/>期刊及獎助同儕審查都已有跨國性的合作成 <lb/>國合作，共同選定大學教職聘用 升遷同儕 <lb/>審查的基本評審指標(Harley &amp; Acord, 2011; <lb/>Weiser, 2012)。 <lb/>期刊同儕審查之跨國合作較早，國際醫 <lb/>學期刊編輯委員會(International Committee <lb/>of Medical Journal Editors, ICMJE)於1979 <lb/>出 版 《 生 物 醫 學 期 投 稿 統 一 規 範 》 <lb/>(Uniform Requirements for <lb/>Submitted Biomedical Journals)，提供作 <lb/>者及期刊編輯參考。2013年該委員會大幅修 <lb/>訂《統一規範》並更名為《學術研究的管 <lb/>理、報告、編輯與出版在醫學期刊之建議 <lb/>規範》(Recommendations for the Conduct, <lb/>Reporting, Editing and Publication of Scholarly <lb/>Work in Medical Journals)，詳列作者、評 <lb/>能與責任，並強調同儕審查是科學研究過程 <lb/>中不可或缺的一環(International Committee <lb/>of Medical Journal Editors, 2013)。委員會除 <lb/>範》外，並定期更新內容，最新版已於2015 <lb/>年12月出版。 <lb/>獎助同儕審查機構的跨國合作發展較 <lb/>遲，歐洲研究機構負責人協會(European <lb/>of Research Councils)及歐洲科學基 <lb/>金(European Science Foundation, ESF)有 <lb/>感於歐洲各國獎助類型與同儕審查作業的多 <lb/>樣性，於2010年合作推動跨國性調查，並於 <lb/>次年出版《歐洲同儕審查指南》(European <lb/>Peer Review Guide)。全書的第一部分為獎 <lb/>助同儕審查作業概覽，說明獎助的類型與差 <lb/>部分則分別論述不同類型的獎助計畫，包括 <lb/>科學網絡創設與強化計畫，以及區域研究 <lb/>中心與研究基礎設施建置計畫等(European <lb/>Science Foundation, 2011a, 2011b)。 <lb/>此 外 美 國 N S F 為 了 建 立 獎 助 同 儕 審 <lb/>查 的 核 心 價 值 ， 於 2 0 1 2 年 首 度 召 開 全 球 <lb/>科 學 同 儕 審 查 高 峰 會 ， 共 有 近 5 0 國 ( 多 <lb/>為G20及O E C D的會員國)的獎助機構代 <lb/>表 與 會 ， 會 中 決 議 建 立 全 球 研 究 委 員 會 <lb/>(Global Research Council, GRC)，並 <lb/>提 出 科 學 同 儕 審 查 六 項 原 則 聲 明 ， 包 括 <lb/>專家評審(expert assessment)、透明性 <lb/>(transparency)、公平性(impartiality)、 <lb/>切 性 ( a p r o p r i a t e n e s ) 、 機 密 性 <lb/>(confidentiality)，以及誠信與道德考量 <lb/>(integrity and ethical considerations)；聲 <lb/>明中亦強調獎助機構作為公共資金的管理 <lb/></body>

			<page>66 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>者，必須展示它們對於送審之研究計畫具有 <lb/>策目標；而嚴謹且透明的同儕審查作業，將 <lb/>有助於確保政府的獎助經費應用在最能促進 <lb/>科學發展及解決社會問題的計畫上(Global <lb/>Research Council, 2012)。 <lb/>二、 同儕審查與書目計量 <lb/>學術界除了進行同儕審查的研究外， <lb/>也積極尋求改進或替代方案。近年來期刊同 <lb/>儕審查受到網路科技及電子出版的影響， <lb/>已出現許多創新作法而呈現多元發展。至於 <lb/>獎助計畫及大學教職聘用 升遷同儕審查， <lb/>合關係，有些學者認為廣泛且多樣的書目 <lb/>計量指標有助於提升同儕審查的合理性與 <lb/>透明性(Bornmann, 2011a, 2013a; van Raan, <lb/>2005)。Geisler(2001)指出同儕審查與書 <lb/>目計量的結合應用，讓同儕審查的決定不再 <lb/>只是評審者的主觀意見，也加入了客觀的量 <lb/>化指標；但是如何將書目計量的量化資訊妥 <lb/>中，是學術界面臨的重大挑戰。 <lb/>書目計量與科學影響力 <lb/>Alan Pritchard在1960年代提出書目計 <lb/>量，用統計方法呈現已紀錄的資訊，例如 <lb/>計算專書、文獻、出版品，以及引用的數值 <lb/>(Bornmann, 2013a)，其中引用數據已逐漸 <lb/>2005; Garfield &amp; Welljamsdorof, 1992; Smith, <lb/>1981)。Merton(1988)認為文獻引用在知 <lb/>識傳遞與擴散上具有雙重意義，在工具意義 <lb/>上，引用代表可能具有參考價值的資訊；而 <lb/>在系統意義上，引用是科學家在知識的智慧 <lb/>財產資料庫中，對於同儕的研究成果進行認 <lb/>知註記。 <lb/>許多學者質疑引用的動機並指出引文 <lb/>可議，以及引文資料庫的正確性不足等；甚 <lb/>至有學者認為學術傳播系統本不完美，出版 <lb/>品的重要性不等同於影響力，而且被大量引 <lb/>用的文獻也未必一定是高品質(Bornmann, <lb/>2011a; Laloë &amp; Mosseri, 2009; &amp; Irvin, <lb/>1983; P e t e r s &amp; v a n R a a n, 1994)。不過 <lb/>Bornmann與Daniel(2006)回顧1960至2005 <lb/>數研究證實引用動機不只是對於科學家同儕 <lb/>之智識與認知影響表達認同，也受到其他非 <lb/>科學價值因素的影響。但是這些研究被視為 <lb/>缺乏信度，因為各篇的研究設計差異甚大， <lb/>研究結果幾乎無法複製，而且很多文獻在方 <lb/>法論上有其缺陷。 <lb/>Van Raan(2005)認為許多研究顯示 <lb/>引用動機並非如此的不同或隨機，反而在許 <lb/>多情況下，引文分析確實是影響力的可靠指 <lb/>標。支持引文分析的學者表示，儘管許多學 <lb/>者認為同儕審查是品質保證的象徵，但是對 <lb/>於大多數的人來說，同儕審查只是提供出版 <lb/>品給科學社群，但是接受度(引用)才是 <lb/>影響力的代表(Bornmann, 2013a; Shadbolt, <lb/>Brody, Carr, &amp; 2006)。Research <lb/>Evaluation and Policy Project(2005)指出雖 <lb/></body>

			<page>67 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<body>然研究品質的評鑑需由同儕進行，但是許多 <lb/>國家的政策已逐漸將影響力視為品質的代理 <lb/>指標。 <lb/>(二) 同儕審查與書目計量的互補性 <lb/>質性的同儕審查與量化的書目計量是當 <lb/>前學術領域的兩大評審方式，各有其支持者， <lb/>也受到許多批評。許多文獻探討同儕審查與 <lb/>書目計量的互補關係，有些學者認為學術評鑑 <lb/>應始自學術價值、終於學術影響力，因此同儕 <lb/>審查必須結合書目計量，才得以完整呈現學術 <lb/>評鑑的全貌(Borgman, 2007; Bornmann, 2011a; <lb/>The British Academy, 2007; Pendlebury, 2008)。 <lb/>Wouter(1997)以資訊流的觀點提出科學知識 <lb/>循環模式，分析同儕審查與書目計量的循環互 <lb/>Van Raan(1996)認為書目計量指標不 <lb/>應該單獨使用，建議將強調研究表現的書目 <lb/>計量指標(尤其是引用數據)納入同儕審查 <lb/>的評審過程之中，以作為評審者的重要參考 <lb/>資訊。此一作法使得同儕審查不再只是少數 <lb/>解受評者在全球研究前沿的地位、影響力與 <lb/>特殊性，並可進一步洞察科學傳播模式與知 <lb/>識散佈過程，此即所謂的「資訊充分的同儕 <lb/>審查」(informed peer review)。Bornmann <lb/>(2013a)指出書目計量與同儕審查整合的 <lb/>效益有二，其一、廣泛且重要的書目計量指 <lb/>標，有助提升同儕審查的透明性與合理性； <lb/>其二、書目計量可以檢驗同儕審查的結果， <lb/>以避免學閥派系效應，而此點正是同儕審查 <lb/>的根本問題。他也認為書目計量指標必須經 <lb/>鑑受評者的專業表現。 <lb/>如歐洲許多國家採行的高等教育機構評鑑， <lb/>即同時包括同儕審查與書目計量指標。但是 <lb/>此一方式應用在個人層級的評鑑時，就引發 <lb/>較多爭議，如何選擇適當的書目計量指標、 <lb/>如何兼顧領域的差異性，以及如何分配兩者 <lb/>的權重等，都是受到關切的議題，這些亦是 <lb/>獎助計畫與大學教職聘用 升遷同儕審查必 <lb/>須面對的重要議題(Abramo &amp; D&apos;Angelo, 2011; <lb/>Bertocchi, Gambardella, Jappelli, Nappi, &amp; Peracchi, <lb/>Cabezas-Clavijo, Robinson-García, Escabias, <lb/>&amp; Jiménez-Contreras, 2013; Harley &amp; Acord, 2011; <lb/>Harley et al., 2010; Weingart, 2005)。 <lb/>陸、 結語 <lb/>在人類的活動中，科學研究可能是受 <lb/>到最多檢驗與評鑑的項目之一(L a l o ë &amp; <lb/>Mosseri, 2009)，以確保研究品質，並做為 <lb/>學術有限資源的分配機制。但是同儕審查有 <lb/>其先天限制，一者是評審乃人類的行為， <lb/>容易受到人性弱點或偏見的影響；一者是 <lb/>評審者擁有極大的權力，但是卻強調保密 <lb/>性(Geisler, 2000; Wenneras &amp; Wold, 1997; <lb/>Ziman, 2000)，因此招致「黑盒子」之批 <lb/>評，甚至有學者認為繼續採行同儕審查的唯 <lb/>一理由是：缺乏其他更好的方法(Kostoff, <lb/>2004; Rennie, 1986; Sieber, 2006)。 <lb/></body>

			<page>68 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<body>若就科學自治的精神來看，同儕審查 <lb/>的正當性是基於學術社群成員之間的彼此信 <lb/>賴與誠信。英國人文社會科學院的同儕審查 <lb/>報告指出，評審者在審查文件時，可以接觸 <lb/>到其他同儕的原始資料組、新的實徵結果， <lb/>或是創新概念架構。這些資訊在商場上都被 <lb/>視為是商業機密，但是在學術領域中，評審 <lb/>者卻是扮演科學管控系統的一環，其終極目 <lb/>標在於快速有效地傳播研究成果，因此評審 <lb/>者的誠信就非常重要(The British Academy, <lb/>各種偏見、評審者之間的一致性過低，以及 <lb/>評審效用難以證實等，必須強化同儕審查的 <lb/>公平性、合理性，以及透明性。 <lb/>今天同儕審查已經普遍受到學術界的重 <lb/>視，而成為各項學術活動的主要仲裁者。不 <lb/>過學術領域越來越專精且複雜，研究人口 <lb/>也愈來愈多，在學術資源未見大幅成長的 <lb/>背景下，競爭將日趨激烈，同儕審查研究 <lb/>的益受重視將不言可喻。證諸目前許多著 <lb/>名同儕審查期刊的稿件接受率只有個位數 <lb/>字，各國政府與民間獎助機構之獲獎率也 <lb/>有逐年下降的趨勢(National Institutes of <lb/>2013; National Foundation, <lb/>2011; P o w e l l, 2010; R C U K, 2006)，另 <lb/>外大學教職聘用與升遷的評審方式亦已受 <lb/>到 公 平 性 的 批 評 。 因 此 未 來 同 儕 審 查 <lb/>立 一 個 持 續 監 督 、 檢 驗 與 改 進 的 機 制 ， <lb/>應是學術界的共同努力方向(B o r n m a n n <lb/>&amp; Daniel, 2008; Callaham, 2003; De Vries <lb/>e t a l., 2009; G l u c k m a n, 2012; G o d l e e <lb/>Jefferson, 2003; Henly &amp; Dougherty, <lb/>Hojat, Gonnella, &amp; Caelleigh 2003; <lb/>Langfeldt, 2001; Rennie, 2003)。 <lb/></body>

			<listBibl>References <lb/>Abbott, A. (2008, June). Publication and the <lb/>future of knowledge. Paper presented at <lb/>the Association of American University <lb/>Presses, Montreal, Canada. Retrieved from <lb/>http://home.uchicago.edu/~aabbott/Papers/ <lb/>aaup.pdf <lb/>Abdoul, H., Perrey, C., Amiel, P., Tubach, <lb/>F., Gottot, S., Durand-Zaleski, I., <lb/>Alberti, C. (2012). Peer review of grant <lb/>applications: Criteria used and qualitative <lb/>study of reviewer practices. PLoS ONE, <lb/>7(9), e46054. d o i: 10.1371/j o u r n a l. <lb/>H., Perrey, C., Tubach, F., Amiel, P., <lb/>I., &amp; Alberti, C. (2012). <lb/>Non-financial conflicts of interest in <lb/>academic grant evaluation: A qualitative <lb/>study of multiple stakeholders in France. <lb/>PLoS ONE, 7(4), e35247. doi: 10.1371/ <lb/>Abramo, G., &amp; D&apos;Angelo, C. (2011). Evaluating <lb/>From informed peer review to <lb/>Scientometrics, 87(3), 499-<lb/>514. doi: 10.1007/s11192-011-0352-7 <lb/>Consortium. (2014). <lb/>for good evaluation practice with the <lb/>portfolio. Retrieved from <lb/>http://research-acumen.eu/wp-content/ <lb/></listBibl>

			<page>69 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<listBibl>u p l o a d s/D6.14-G o o d-E l u a t i o n-<lb/>Practices.pdf <lb/>L. K. (1996). The Ingelfinger rule, <lb/>embargoes, and journal peer <lb/>1. The Lancet, 347(9012), 1382-1386. doi: <lb/>10.1016/S0140-6736(96)91016-8 <lb/>American Association for the Advancement <lb/>of Science. (2010). R&amp;D <lb/>e a r m a r k s b y a g e n y a n d p ro g r a m . <lb/>Retrieved from http://www.aaas.org/sites/ <lb/>American Association of University Professors. <lb/>(1915). AAUP&apos;s 1915 declaration of <lb/>principles. Retrieved from http://aaup.org. <lb/>uiowa.edu/files/aaup.org.uiowa.edu/files/ <lb/>American Association of University Professors. <lb/>(1940). 1940 statement of principles on <lb/>freedom and tenure. Retrieved <lb/>http://www.aaup.org/file/1940%20 <lb/>Statement.pdf <lb/>American Association of University Professors. <lb/>(1966). Statement on government of <lb/>colleges and universities. Retrieved from <lb/>http://www.aaup.org/report/statement-<lb/>government-colleges-and-universities <lb/>Ander s e n, D. L. (E d.). (2003). D i g i t a l <lb/>in the tenure, promotion, <lb/>and review process. New York, NY: <lb/>M. E. Sharpe. <lb/>W. G., Waeckerle, J. F., Berlin, J. A., &amp; <lb/>Callaham, M. L. (1998). Who reviews the <lb/>Feasibility of using a fictitious <lb/>manuscript to evaluate peer reviewer <lb/>performance. Annals of Emergency <lb/>Medicine, 32(3), 310-317. doi: 10.1016/ <lb/>S0196-0644(98)70006-X <lb/>T., &amp; Trowler, P. (2001). <lb/>tribes and territories: Intellectual <lb/>and the culture of disciplines <lb/>ed.). Buckingham, England: Open <lb/>Press. <lb/>Bell, S., Shaw, B., &amp; Boaz, A. (2011). Real-<lb/>w o r l d a p p r o a c h e s t o a s s e s s i n g t h e <lb/>impact of environmental research on <lb/>policy. Research Evaluation, 20(3), 227-<lb/>237. doi: 10.3152/095820211X1311858 <lb/>3635792 <lb/>G., Gambardella, A., Jappelli, T., <lb/>Nappi, C. A., &amp; Peracchi, F. (2015). <lb/>Bibliometric evaluation vs. informed peer <lb/>review: Evidence from Italy. Research <lb/>Policy, 44(2), 451-466. doi: 10.1016/ <lb/>j.respol.2014.08.004 <lb/>Bertout, C., &amp; Schneider, P. (2004). Editorship <lb/>and peer-review at A&amp;A. <lb/>a n d A s t ro p h y s i c s , 4 2 0(3), E1. d o i: <lb/>10.1051/0004-6361:20040182 <lb/>E., James, R., &amp; Arkoudis, S. (2011). <lb/>The Australian academic profession <lb/>transition. Retrieved from http:// <lb/>careers.unimelb.edu.au/__data/assets/ <lb/>pdf_file/0003/723315/The_Academic_ <lb/>Profession_in_Transition_Sept2011.pdf <lb/>Bhattacharya, A. (2012). Science funding: Duel <lb/>to the death. Nature, 488(7409), 20-22. <lb/>doi: 10.1038/488020a <lb/>Biagioli, M. (2002). From book censorship <lb/>academic peer review. <lb/>J o u r n a l f o r t h e S t u d y o f M e d i a &amp; <lb/></listBibl>

			<page>70 <lb/></page>

			<note place="headnote">第1期 (2016.6) <lb/></note>
			
			<listBibl>Composite 12(1), 11-45. doi: <lb/>10.1080/1045722022000003435 <lb/>Bloch, C., Graversen, E. K., &amp; Pedersen, H. S. (2014). <lb/>Competitive research grants and their impact <lb/>on career performance. Minerva, 52(1), 77-96. <lb/>doi: 10.1007/s11024-014-9247-0 <lb/>M., Ash, E., Edge, D., Reece, C., <lb/>J., &amp; Williams, P. (1990). <lb/>review: A report to the advisory board for <lb/>the research councils from the working <lb/>group on peer Retrieved from <lb/>http://webarchive.nationalarchives. <lb/>g o v.u k/20160217110318/h t t p://m r c. <lb/>ac.uk/Utilities/Documentrecord/index. <lb/>htm?d=MRC003951 <lb/>Borgman, C. L. (2007). Scholarship in the digital <lb/>Information, infrastructure, and the <lb/>internet. Cambridge, MA: MIT Press. <lb/>Bornmann, L. (2010). Does the journal peer <lb/>select the from the work <lb/>The state of empirical research. <lb/>IETE Technical Review, 27(2), 93-96. doi: <lb/>10.4103/0256-4602.60162 <lb/>Bornmann, L. (2011a). Peer review and <lb/>Potentials and problem. In J. <lb/>C. Shin, R. K. Toutkoushian, &amp; U. Teichler <lb/>University rankings: Theoretical <lb/>basis, methodology and impacts on global <lb/>higher education (pp. 145-164). Berlin, <lb/>Springer. doi: 10.1007/978-94-<lb/>Bornmann, L. (2011b). Scientific peer review. <lb/>Annual Review of Information Science and <lb/>Technology, 45(1), 197-245. doi: 10.1002/ <lb/>aris.2011.1440450112 <lb/>Bornmann, L. (2012). Measuring the societal <lb/>of research. EMBO Reports, 13(8), <lb/>673-676. doi: 10.1038/embor.2012.99 <lb/>Bornmann, L. (2013a). Evaluations by peer <lb/>in science. Springer Science <lb/>Reviews, 2013(1), 1-4. doi: 10.1007/ <lb/>s40362-012-0002-3 <lb/>L. (2013b). What is societal impact of <lb/>research and how can it be assessed? A literature <lb/>survey. Journal of the American Society for <lb/>Information Science and Technology, <lb/>217-233. doi: 10.1002/asi.22803 <lb/>Bornmann, L., &amp; Daniel, H.-D. (2005). Criteria <lb/>used by a peer review committee for <lb/>of research fellows: A Boolean <lb/>analysis. International Journal of <lb/>Selection and Assessment, 13(4), 296-303. <lb/>doi: 10.1111/j.1468-2389.2005.00326.x <lb/>Bornmann, L., &amp; Daniel, H.-D. (2006). What <lb/>do citation counts measure? A review <lb/>of studies on citing behavior. <lb/>of Documentation, 64(1), 45-80. doi: <lb/>10.1108/00220410810844150 <lb/>L., &amp; Daniel, H.-D. (2008). The <lb/>of the peer review process: <lb/>Inter-referee agreement and predictive <lb/>of manuscript refereeing at <lb/>AngewandteChemie. AngewandteChemie <lb/>International Edition, 47(38), 7173-7178. <lb/>doi: 10.1002/anie.200800513 <lb/>o r n m a n n, L., &amp; D a n i e l, H.-D. (2010). <lb/>of reviewers&apos; ratings when <lb/>using public peer review: A case study. <lb/>Learned Publishing, 23(2), 124-131. doi: <lb/>10.1087/20100207 <lb/></listBibl>

			<page>71 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>
			
			<listBibl>Bornmann, L., Leydesdorff, L., &amp; van den <lb/>Besselaar, P. (2010). A meta-evaluation <lb/>of scientific proposals: Different <lb/>of comparing rejected to awarded <lb/>applications. Journal of Informetrics, 4(3), <lb/>211-220. doi: 10.1016/j.joi.2009.10.004 <lb/>L., &amp; Marx, W. (2014). How to <lb/>evaluate individual researchers working in <lb/>the natural and life sciences meaningfully? <lb/>A p r o p o s a l o f m t h o d s b a s e d o n <lb/>citations. Scientometrics, <lb/>98(1), 487-509. doi: 10.1007/s11192-013-<lb/>1161-y <lb/>L., Marx, W., Schier, H., Thor, <lb/>A., &amp; D a n i e l, H.-D. (2010). F r o m <lb/>black box to white box at open access <lb/>journals: Predictive validity of manuscript <lb/>reviewing and editorial decisions at <lb/>Atmospheric Chemistry and Physics. <lb/>Evaluation, 19(2), 105-118. doi: <lb/>10.3152/095820210X510089 <lb/>B o r n m a n n, L., M u t z, R., &amp; D a n i e l, H.-<lb/>(2008). Latent Markov modeling <lb/>applied to grant peer review. Journal of <lb/>Informetrics, 2(3), 217-228. doi: 10.1016/ <lb/>j.joi.2008.05.003 <lb/>Bornmann, L., Nast, I., &amp; Daniel, H.-D. (2008). <lb/>editors and referees look for signs of <lb/>misconduct when reviewing <lb/>manuscripts? A quantitative content <lb/>analysis of studies that examined review <lb/>criteria and reasons for accepting and <lb/>manuscripts for publication. <lb/>Scientometrics, 77(3), 415-432. doi: <lb/>10.1007/s11192-007-1950-2 <lb/>Boyer, E. L. (1997). Scholarship -A personal <lb/>journey. In C. E. Glassick, M. T. Huber, &amp; <lb/>G. I. Maeroff (Eds.), Scholarship assessed: <lb/>Evaluation of the professoriate (Special <lb/>report). San Francisco, CA: Jossey-Bass. <lb/>B., &amp; Boardman, C. (2009). Broad <lb/>impacts and narrow perspectives: Passing <lb/>buck on science and social impacts. <lb/>Social Epistemology, 23(3/4), 183-198. <lb/>doi: 10.1080/02691720903364019 <lb/>Braben, D. W. (2004). Pioneering research: A <lb/>worth taking. Hoboken, NJ: Wiley. <lb/>D. W. (2011, October). How to identify <lb/>people who might radically change the <lb/>way we think about an important subject. <lb/>Paper presented at the Danish National <lb/>Research Foundation Annual Meeting, <lb/>Copenhagen, Denmark. Retrieved from <lb/>http://dg.dk/filer/20_aars_jubilaeum/ <lb/>The British Academy. (2007). Peer review: The <lb/>challenges for the humanities and social <lb/>Retrieved from http://www. <lb/>Brooks, J. H. (1988). Confidentiality of tenure <lb/>review and discovery of peer review <lb/>materials. Brigham Young University Law <lb/>Review, 1988(4), 706-752. <lb/>B r o w n, R. S., &amp; K u r l a n d, J. E. (1990). <lb/>Academic tenure and academic freedom. <lb/>and Contemporary Problems, <lb/>325-355. doi: 10.2307/1191800 <lb/>B r o w n, T. (2004). P e e r re v i e w a n d t h e <lb/>acceptance of new scientific ideas. <lb/>London, England: Sense about Science. <lb/></listBibl>

			<page>72 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>
			
			<listBibl>B u r n a m, J. (1990). T h e e v o l u t i o n <lb/>of editorial peer review. Journal of <lb/>the American Medical Association, <lb/>2 6 3(10), 1323-1329. o i: 10.1001/ <lb/>jama.263.10.1323 <lb/>Burnham, J. C., Sauer, J. E., &amp; Gibbs, R. D. <lb/>(1987). Peer-reviewed grants in <lb/>trade research. Science, <lb/>&amp; Human Values, 12(2), <lb/>A., Robinson-García, N., <lb/>Escabias, M., &amp; Jiménez-Contreras, <lb/>E. (2013). R e v i e w e r s &apos; r a t i n g s a n d <lb/>bibliometric indicators: Hand in hand <lb/>when assessing over research proposals? <lb/>PLoS ONE, 8(6), e68258. doi: 10.1371/ <lb/>journal.pone.0068258 <lb/>Callaham, M. (2003). The evaluation and <lb/>training of peer reviewers. In F. Godlee &amp; <lb/>T. Jefferson (Eds.), Peer review in health <lb/>science (pp. 164-182). London, England: <lb/>Publishing Group. <lb/>C a m e r o n, M. (2010). F a c u l t y t e n u r e i n <lb/>academe: The evolution, benefits and <lb/>of an important tradition. <lb/>Journal of Student Affairs at New York <lb/>4, 1-11. <lb/>C h u b i n , D . E . ( 1 9 9 4 ) . G r a n t s p e e r <lb/>r e v i e w i n t h e o r y a n d p r a c t i c e . <lb/>Evaluation Review, 18(1), 20-30. doi: <lb/>10.1177/0193841X9401800103 <lb/>Chubin, D. E., &amp; Hackett, E. J. (1990). Peerless <lb/>science: Peer review and U.S. science <lb/>New York, NY: State University of <lb/>New York Press. <lb/>C h u b i n, D. E., &amp; H a c k e t t, E. J. (2003, <lb/>Peer review for the 21st <lb/>century: Applications to education <lb/>r e s e a r c h . P a p e r p r e s e n t e d a t <lb/>on the Peer Review of <lb/>Education Research Grant Applications, <lb/>Washington, DC. <lb/>Cicchetti, D. V. (1991). The <lb/>peer review for manuscript and grant <lb/>s u b m i s s i o n s: A c r o s s-d i s c i p l i n a r y <lb/>Behavioral and Brain <lb/>Sciences, 14(1), 119-135. doi: 10.1017/ <lb/>S0140525X00065675 <lb/>D. V. (1997). Referees, editors, <lb/>and publication practices: Improving <lb/>the reliability and usefulness of the peer <lb/>system. Science and Engineering <lb/>Ethics, 3(1), 51-62. doi: 10.1007/s11948-<lb/>997-0016-4 <lb/>J. R. (2000). The role of journals in the <lb/>growth of scientific knowledge. In B. <lb/>&amp; H. B. Atkins (Eds.), The web <lb/>of knowledge: A festschrift in honor of <lb/>Eugene Garfield (pp. 109-142). Medford, <lb/>NJ: Information Today. <lb/>C o l e, J. R., &amp; C o l e, S. (1973). S o c i a l <lb/>stratification in science. Chicago, IL: <lb/>University of Chicago Press. <lb/>Cole, S. (1992). science: Between <lb/>nature and society. Cambridge, MA: <lb/>Harvard University Press. <lb/>Cole, S., Cole, J. R., &amp; Simon, G. A. (1981). <lb/>Chance and consensus in peer review. <lb/>c i e n c e , 2 1 4(4523), 881-886. d o i: <lb/>10.1126/science.7302566 <lb/></listBibl>

			<page>73 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>
			
			<listBibl>Collins, F. S., &amp; Tabak, L. A. (2014). Policy: <lb/>NIH to enhance reproducibility. <lb/>N a t u r e , 5 0 5(7485), 612-613. d o i: <lb/>10.1038/505612a <lb/>Cozzens, S. E. (1999). Are new accountability <lb/>rules for science? Issues in Science <lb/>and Technology, 15(4). Retrieved from <lb/>http://issues.org/15-4/cozzens/ <lb/>C o z z e n s, S. E. (2001). A u t o n o m y a n d <lb/>accountability for century science. In <lb/>J. de la Mothe (Ed.), Science, technology, <lb/>and governance (pp. 104-115). London, <lb/>England: Pinter. <lb/>Cummings, W. K., M. J. (2012). <lb/>Historical and perspectives <lb/>faculty role in governance. In Scholars <lb/>in the changing American <lb/>(pp. 111-129). Dordrecht, Netherlands: <lb/>doi: 10.1007/978-94-007-2730-<lb/>Daniel, H.-D. (2005). Publications as a measure <lb/>of scientific advancement and of scientists&apos; <lb/>productivity. Learned Publishing, 18, 143-<lb/>148. doi: 10.1087/0953151053584939 <lb/>Vries, D. R., Marschall, E. A., &amp; Stein, R. A. <lb/>(2009). Exploring the peer review process: <lb/>What is it, does it work, and can it be <lb/>improved? Fisheries, 34(6), 270-279. doi: <lb/>10.1577/1548-8446-34.6.270 <lb/>Dearing, R. (1997). Higher education in the <lb/>learning society report]. Leeds, <lb/>England: National Committee of Inquiry <lb/>into Higher Education. <lb/>Demicheli, V., &amp; Di Pietrantonj, C. (2007). <lb/>Peer review for improving the quality of <lb/>grant applications. In Cochrane <lb/>of systematic reviews (Issue 2). Hoboken, <lb/>J: Wi l e y. d o i: 10.1002/14651858. <lb/>Donovan, C. (2011). State of the art in assessing <lb/>research impact: Introduction to a special <lb/>issue. Research Evaluation, 20(3), 175-179. <lb/>doi: 10.3152/095820211X13118583635918 <lb/>D. L. (1991). When nonreliability of <lb/>reviews indicates solid science. <lb/>Brain Sciences, 14(1), 145-146. doi: <lb/>10.1017/S0140525X00065791 <lb/>England, J. M. (1982). A patron for pure <lb/>science: The National Science Foundation&apos;s <lb/>formative years, 1945-57. Washington, DC: <lb/>National Science Foundation. <lb/>European Science Foundation. (2011a). ESF <lb/>survey analysis report on peer review <lb/>practices. from http://www. <lb/>esf.org/fileadmin/Public_documents/ <lb/>Publications/pr_guide_survey.pdf <lb/>European Science Foundation. (2011b). European <lb/>peer review guide: Integrating policies <lb/>and practices into coherent procedures. <lb/>Retrieved from https://www.vr.se/downlo <lb/>ad/18.2ab49299132224ae10680001647/ <lb/>Fairweather, J. (2005). Beyond the rhetoric: <lb/>in the relative value of teaching <lb/>and research in faculty salaries. <lb/>Journal of Higher Education, 76(4), 401-<lb/>422. doi: 10.1353/jhe.2005.0027 <lb/>a n g, H. (2011). P e e r r e v i e w a n d o v e r-<lb/>competitive research funding fostering <lb/>m a i n s t r e a m o p i n i o n t o m o n o p o l y. <lb/></listBibl>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<listBibl>Scientometrics, 87, 10.1007/ <lb/>s11192-010-0323-4 <lb/>R. H., &amp; Fletcher, S. W. (2003). The <lb/>effectiveness of journal In F. <lb/>Godlee &amp; T. Jefferson (Eds.), Peer review <lb/>in science (pp. 62-75). London, <lb/>BMJ Publishing Group. <lb/>Ford, E. (2013). Defining and characterizing <lb/>p e n p e e r r e v i e w: A r e i e w o f t h e <lb/>Journal of Scholarly Publishing, <lb/>44(4), 311-326. doi: 10.3138/jsp.44-4-001 <lb/>R., &amp; Briggle, A. (2012). The <lb/>dedisciplining of peer review. Minerva, 50(1), <lb/>3-19. doi: 10.1007/s11024-012-9192-8 <lb/>R., &amp; Holbrook, J. (2012, March). <lb/>The promise and perils of transformative <lb/>research. Paper presented at the Workshop <lb/>on the research: Ethical <lb/>and societal implications, National Science <lb/>Arlington, VA. Retrieved from <lb/>Frodeman, R., Holbrook, J., &amp; Mitcham, C. <lb/>Part I: Defining peer review. In <lb/>Frodeman, J. Holbrook, C. Mitcham, <lb/>&amp; H. X i a o n a n (E d s.), P e e r re v i e w, <lb/>research integrity, and the governance <lb/>of science: Practice, theory, and current <lb/>discussions. Beijing, China: People&apos;s <lb/>Publishing House. <lb/>Garfield, E., &amp; Sher, I. H. (1963). New factors <lb/>in the evaluation of scientific literature <lb/>through citation indexing. American <lb/>Documentation, 14(3), 195-201. <lb/>10.1002/asi.5090140304 <lb/>Garfield, E., &amp; Welljamsdorof, A. <lb/>Citation data -Their use as quantitative <lb/>indicators for science and technology <lb/>and policy-making. Current <lb/>49, 5-13. <lb/>Geisler, E. (2000). The metrics of science and <lb/>technology. Westport, CT: Quorum Books. <lb/>E. (2001). The mires of research <lb/>The Scientist, 15(10), 39. <lb/>General Accounting Office. (1999). Federal <lb/>research: Peer review practices at federal <lb/>science agencies vary (GAO/RCED-<lb/>99-99). Washington, DC: United States <lb/>Accounting Office. Retrieved <lb/>from http://science.energy.gov/~/media/ <lb/>M., Spong, C. Y., Simonsen, S. E., <lb/>Martin, S., &amp; Scott, J. R. (2008). Author <lb/>perception of peer review. <lb/>&amp; Gynecology, 112(3), 646-652. doi: <lb/>10.1097/AOG.0b013e31818425d4 <lb/>Gillett, R. (1993). Prescriptions for medical <lb/>research II-Is medical research well <lb/>served by peer review? British Medical <lb/>Journal, 306(6893), 1672-1675. d o i: <lb/>10.1136/bmj.306.6893.1672 <lb/>Giraudeau, B., Leyrat, C., Le Gouge, A., Léger, <lb/>J., &amp; A. (2011). review of <lb/>grant applications: A simple method to <lb/>identify proposals with discordant reviews. <lb/>6(11), e27557. doi: 10.1371/ <lb/>journal.pone.0027557 <lb/>Research Council. (2012). Statement <lb/>o f p r i n c i p l e s f o r s c i e n t i f i c m e r i t <lb/>review. Retrieved from http://www. <lb/></listBibl>

			<page>75 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<listBibl>globalresearchcouncil.org/sites/default/ <lb/>Gluckman, P. (2012). Which science fund: <lb/>Time to review peer review? Auckland, <lb/>N e w Z e a l a n d: O ff i c e o t h e P r i m e <lb/>Science Advisory Committee. <lb/>Retrieved from http://www.pmcsa.org.nz/ <lb/>wp-content/uploads/Which-science-to-<lb/>fund-time-to-review-peer-review.pdf <lb/>Godlee, F., Gale, C. R., &amp; Martyn, C. N. (1998). <lb/>Effect on the quality peer review of <lb/>blinding reviewers and asking them to <lb/>their reports: A randomized controlled <lb/>trial. Journal of the American Medical <lb/>A s s o c i a t i o n , 2 8 0(3), 237-240. d o i: <lb/>10.1001/jama.280.3.237 <lb/>Godlee, F., &amp; Jefferson, T. (2003). Introduction. <lb/>In F. Godlee &amp; T. Jefferson (Eds.), Peer <lb/>review in health sciences (pp. xiii-xv). <lb/>London, England: BMJ Publishing Group. <lb/>Goldman, R. L. (1994). The reliability of peer <lb/>assessments: A meta-analysis. Evaluation <lb/>the Health Professions, 17, doi: <lb/>10.1177/016327879401700101 <lb/>Greenbank, P. (2006). The academic&apos;s <lb/>need for re-evaluation? Teaching in <lb/>Higher Education, 11(1), 107-112. doi: <lb/>10.1080/13562510500400248 <lb/>A., Gala, S., Jaccard, J., &amp; <lb/>Vetter, L. (2015). Being honest about <lb/>tenure in the United States: The need for <lb/>tenure system reform within institutions <lb/>higher education. International Journal <lb/>of Social Science Studies, 3(4), 25-36. doi: <lb/>Guston, D. H. (2003). The expanding role <lb/>of peer review processes in the United <lb/>In P. Shapira &amp; S. Kuhlmann <lb/>d s.), L e a r n i n g f ro m s c i e n c e a n d <lb/>t e c h n o l o g y p o l i c y e v a l u a t i o n : <lb/>Experiences from the United States <lb/>and Europe (pp. 81-97). Cheltenham, <lb/>England: Edward Elgar. <lb/>Guthrie, S., Guérin, B., Wu, H., Ismail, S., <lb/>&amp; Wooding, S. (2013). to <lb/>review in research project funding <lb/>(RR-139-DH). Santa Monica, CA: Rand <lb/>Corporation. Retrieved from http://www. <lb/>rand.org/content/dam/rand/pubs/research_ <lb/>reports/RR100/RR139/RAND_RR139.pdf <lb/>E. J. (1997). Peer review in science <lb/>science policy. In M. S. Frankel (Ed.), <lb/>East-west dialogue on research evaluation <lb/>in post-communist Europe (pp. 51-60). <lb/>Budapest, Hungary: Central European <lb/>Press. <lb/>Harley, D., &amp; Acord, S. K. (2011). Peer review <lb/>in academic promotion and publishing: Its <lb/>meaning, locus, and future. Berkeley, CA: <lb/>Center for Studies in Higher Education, <lb/>UC Berkeley. <lb/>D., Acord, S. K., Earl-Novell, S., <lb/>a w r e n c e, S., &amp; K i n g, C. J. (2010). <lb/>Assessing the future landscape of scholarly <lb/>communication: An exploration of faculty <lb/>values and needs in seven disciplines. <lb/>Berkeley, CA: UC Berkeley, for <lb/>Education. <lb/>S. (1996). Implementing review <lb/>the net: Scientific quality control in <lb/></listBibl>

			<page>76 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>
			
			<listBibl>scholarly electronic journals. In R. Peek <lb/>&amp; G. Newby (Eds.), Scholarly publishing: <lb/>The electronic frontier (pp. 103-118). <lb/>Cambridge, MA: MIT Press. <lb/>Harnad, S. (2000). invisible hand of peer <lb/>review. Retrieved from http://cogprints. <lb/>org/1646/ <lb/>Heitman, (2002). The roots of honor and <lb/>integrity in science: Historical themes <lb/>in the practical ethics of research. In R. <lb/>Bulger, E. Heitman, &amp; S. J. Reiser <lb/>(Eds.), The ethical dimensions of the <lb/>biological and health sciences 21-<lb/>Cambridge, England: Cambridge <lb/>University Press. <lb/>F. (2010). our lesson: Review <lb/>of quality teaching in higher education. <lb/>Paris, France: Organization for Economic <lb/>Cooperation and Development. <lb/>Henly, S. J., &amp; Dougherty, M. C. (2009). <lb/>Quality of manuscript reviews in nursing <lb/>research. Nurs Outlook, 57, 18-26. doi: <lb/>10.1016/j.outlook.2008.05.006 <lb/>D. M., &amp; Katz, J. S. (1996). Where <lb/>is Technology <lb/>&amp; Human 21(4), 379-406. doi: <lb/>10.1177/016224399602100401 <lb/>The Higher Education Academy. (2009). <lb/>e w a rd a n d re c o g n i t i o n i n h i g h e r <lb/>education: Institutional policies and their <lb/>implementation. Retrieved from https:// <lb/>rewardandrecognition_2_2.pdf <lb/>Hodgson, C. (1997). How reliable is peer <lb/>review? An examination of operating grant <lb/>proposals simultaneously submitted to two <lb/>similar peer review systems. of <lb/>Clinical Epidemiology, 50(11), 1189-1195. <lb/>doi: 10.1016/S0895-4356(97)00167-4 <lb/>Hojat, M., Gonnella, J. B., &amp; Caelleigh, <lb/>(2003). Impartial judgment by the <lb/>of science: Fallibility <lb/>and accountability in the peer review <lb/>process. in Health Sciences <lb/>8(1), 75-96. doi: 10.1023/ <lb/>A:1022670432373 <lb/>J. B. (2010). The use of societal <lb/>impacts considerations in grant proposal <lb/>peer review: A comparison of five models. <lb/>Technology &amp; Innovation, 12(3), 213-224. <lb/>doi: 10.3727/194982410X12895770314078 <lb/>Holbrook, J. B. (2012). Re-assessing the <lb/>-society relation: The case of <lb/>US National Science Foundation&apos;s <lb/>broader impacts merit review criterion <lb/>(1997-2011). from http:// <lb/>metadc77119/ <lb/>Holbrook, J. B. (2013a, October). review <lb/>of team science research. Paper presented <lb/>the Workshop on Institutional and <lb/>Organizational Supports for Team Science, <lb/>Washington, DC. Retrieved from http:// <lb/>H o l b r o o k , J . B . ( 2 0 1 3 b ) . W h a t i s <lb/>i n r d i s c i p l i n a r y c o m m u n i c a t i o n? <lb/>Reflections on the very idea of disciplinary <lb/>integration. Synthese, 190(11), 1865-1879. <lb/>doi: 10.1007/s11229-012-0179-7 <lb/></listBibl>

			<page>77 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>

			<listBibl>Holbrook, J. B., &amp; Frodeman, R. (2011). Peer <lb/>review and the ex ante assessment of <lb/>societal impacts. Research Evaluation, <lb/>20(3), 239-246. doi: 10.3152/095820211X <lb/>12941371876788 <lb/>J. B., &amp; Hrotic, S. (2013). <lb/>skies, impacts, and peer Roars <lb/>Transactions, a Journal on Research <lb/>P o l i c y a n E v a l u a t i o n , 1(1). o i <lb/>10.13130/2282-5398/2914 <lb/>Hornbostel, S., Böhmer, S., Klingsporn, <lb/>B., Neufeld, J., &amp; von Ins, M. (2009). <lb/>Funding of young scientist scientific <lb/>excellence. Scientometrics, 79(1), 171-<lb/>190. doi: 10.1007/s11192-009-0411-5 <lb/>Horrobin, D. F. (1990). The <lb/>of peer review and the suppression <lb/>innovation. Journal of the American <lb/>Medical Association, 263(10), 1438-1441. <lb/>doi: 10.1001/jama.263.10.1438 <lb/>D. F. (1996). Peer review of grant <lb/>applications: A harbinger for mediocrity <lb/>in clinical research. The Lancet, 348, <lb/>1 2 9 3 -1 2 9 5 . d o i : 1 0 . 1 0 1 6 / S 0 1 4 0 -<lb/>K., Klein, J. T., Bruun, H., <lb/>&amp; H u k k i n e n, J. (2010). A n a l y z i n g <lb/>i n t e r d i s c i p l i n a r i t y: Ty p o l o g y a n d <lb/>indicators. Research Policy, 39(1), 79-88. <lb/>doi: 10.1016/j.respol.2009.09.011 <lb/>International Committee of Medical Journal <lb/>Editors. (2013). Recommendations for <lb/>the conduct, reporting, editing and <lb/>of scholarly work in medical <lb/>Retrieved from http://www. <lb/>scienceofsciencepolicy.net/sites/default/ <lb/>Ismail, S., Farrands, A., &amp; Wooding, S. (2009). <lb/>Evaluating grant peer review in the <lb/>health sciences. Cambridge, England: <lb/>Europe. <lb/>U. W., Marsh, H. W., &amp; Bond, N. <lb/>(2006). A new reader trial approach to <lb/>peer review in funding research grants: <lb/>An Australian experiment. Scientometrics, <lb/>69(3), 591-606. doi: 10.1007/s11192-006-<lb/>0171-4 <lb/>Jefferson, T., Rudin, M., Brodney-Folse, S., &amp; <lb/>Davidoff, F. (2007). Editorial peer review <lb/>for improving the quality of reports of <lb/>studies. Cochrane Database <lb/>of Methodology Reviews, 18(2), No. <lb/>M R000016. d o i: 10.1002/14651858. <lb/>MR000016.pub3 <lb/>A. C., Cho, M. K., Winker, M. A., <lb/>B e r l i n, J. A., R e n n i e, D., &amp; P E E R <lb/>Investigators. (1998). Does masking author <lb/>improve peer review quality? A <lb/>controlled trial. Journal of the <lb/>American Medical Association, 280(3), <lb/>doi: 10.1001/jama.280.3.240 <lb/>Kamenetzky, J. R. (2012). Opportunities for <lb/>impact: Statistical analysis of the National <lb/>Science Foundation&apos;s broader impacts <lb/>criterion. Science and Public Policy, 40(1), <lb/>72-84. doi: 10.1093/scipol/scs059 <lb/>Kostoff, R. N. (1995). Federal research <lb/>impact assessment: Axioms, approaches, <lb/>applications. Scientometrics, 34(2), 163-<lb/>206. doi: 10.1007/BF02020420 <lb/></listBibl>

			<page>78 <lb/></page>

			<note place="headnote">第1期 (2016.6) <lb/></note>
			
			<listBibl>Kostoff, R. N. (2004). Research program peer <lb/>Purposes, principles, practices, <lb/>protocols. VA: Office of <lb/>Research. <lb/>Kreber, C. (2002). Controversy and consensus <lb/>on the scholarship of teaching. Studies in <lb/>Higher Education, 27(2), 151-167. doi: <lb/>10.1080/03075070220119995 <lb/>D. A. (1990). Peer review in 18th-<lb/>century scientific journalism. Journal <lb/>of the American Medical Association, <lb/>6 3(10), 1321-1322. d o i: 10.1001/ <lb/>jama.263.10.1321 <lb/>Lal, B., &amp; Peña, V. (2013, March). Big data <lb/>in evaluating transformative scientific <lb/>research: Concepts and a case study. <lb/>presented at the Workshop on <lb/>Big Data: Measuring the Impact <lb/>o f t h e G o v e r n m e n t &apos; s R e s e a r c h <lb/>n d D e v e l o p m e n t I n v e s t m e n t s, <lb/>DC. <lb/>F., &amp; Mosseri, R. (2009). Bibliometric <lb/>of individual researchers: Not <lb/>even right... not even wrong! <lb/>N e w s , 4 0(5), 26-29. d o i: 10.1051/ <lb/>L a m o n t, M. (2009). H o w p r o f e s s o r s <lb/>t h i n k : I n s i d e t h e c u r i o u s w o r l d o f <lb/>a c a d e m i c j u d g m e n t. C a m b r i d g e, <lb/>Harvard University Press. doi: <lb/>L a n g f e l d t, L. (2001). T h e d e c i s i o n-<lb/>constraints and processes of <lb/>grant peer review, and their effects on <lb/>the review outcome. Studies <lb/>f S c i e n c e , 3 1(6), 820-841. d o i: <lb/>10.1177/030631201031006002 <lb/>L. (2006). The policy challenges of <lb/>peer review: Managing bias, conflict of <lb/>interests and interdisciplinary assessments. <lb/>Research Evaluation, 31-41. doi: <lb/>10.3152/147154406781776039 <lb/>Langfeldt, L., &amp; Kyvik, S. (2011). Researchers <lb/>as evaluators: Tasks, tensions and politics. <lb/>Higher Education, 62(2), 199-212. doi: <lb/>10.1007/s10734-010-9382-y <lb/>Laudel, G., &amp; Glaser, J. (2012). ERC&apos;s <lb/>on the grantees&apos; research and <lb/>their careers (EURECIA, Work package <lb/>4 summary report). Retrieved <lb/>h t t w w.l u l.i n f o/w p-c o n t e n t/ <lb/>uploads/2013/12/EURECIA-WP4-report-<lb/>final-Jan2012.pdf <lb/>A., Bornmann, L., Gannon, F., &amp; <lb/>Wallon, G. (2007). A persistent problem. <lb/>EMBO Reports, 8(11), 982-987. doi: <lb/>10.1038/sj.embor.7401109 <lb/>Lee, C. J., Sugimoto, C. R., Zhang, G., &amp; <lb/>B. (2013). Bias in peer review. <lb/>Journal of the American Society for <lb/>Information Science and Technology, <lb/>64(1), 2-17. doi: 10.1002/asi.22784 <lb/>J. (1984). Peer review: The continual <lb/>n e e d f o r r e a s s e s s m e n t. C a n c e r <lb/>I n v e s t i g a t i o n , 2(4), 311-320. d o i: <lb/>10.3109/07357908409018445 <lb/>L o c k, S. (1985). A d i f f i c u l t b a l a n c e : <lb/>Editorial peer review in medicine. <lb/>London, England: Nuffield Provincial <lb/>Trust. <lb/></listBibl>

			<page>79 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>
			
			<listBibl>Luukkonen, T. (2012). Conservatism and risk-<lb/>taking in peer review: Emerging ERC <lb/>practices. Research Evaluation, 21, 48-60. <lb/>doi: 10.1093/reseval/rvs001 <lb/>Manske, P. T. (1997). review of peer review. <lb/>Journal of Hand Surgery, 767-<lb/>771. doi: 10.1016/s0363-5023(97)80067-6 <lb/>Marsh, H. W., Jayasinghe, U. W., &amp; Bond, N. <lb/>(2008). Improving the peer-review <lb/>process for grant applications: Reliability, <lb/>validity, bias, and generalizability. <lb/>Psychologist, 63(3), <lb/>doi: 10.1037/0003-066X.63.3.160 <lb/>H. W., Jayasinghe, U. W., &amp; Bond, N. <lb/>W. (2011). Gender differences in peer <lb/>reviews of grant applications: A substantive-<lb/>methodological synergy in support of the null <lb/>hypothesis mode. Journal of Informetrics, 5, <lb/>167-181. doi: 10.1016/j.joi.2010.10.004 <lb/>B. R. (2011). The research excellence <lb/>framework and the &quot;impact agenda&quot;: <lb/>Are we creating a Frankenstein monster? <lb/>Research Evaluation, 247-254. doi: <lb/>10.3152/095820211X13118583635693 <lb/>Martin, B. R., &amp; Irvine, J. (1983). Assessing <lb/>basic research: Some partial indicators <lb/>scientific in astronomy. <lb/>Res earch Policy, 12(2), 61-90. d o i: <lb/>10.1016/0048-7333(83)90005-7 <lb/>McNutt, R. A., Evans, A. Fletcher, R. H., <lb/>&amp; Fletcher, S. W. (1990). The effects of <lb/>blinding on the quality of peer review: <lb/>randomized trial. Journal of the American <lb/>Medical Association, 263(10), 1371-1376. <lb/>doi: 10.1001/jama.1990.03440100079012 <lb/>Merton, R. K. (1942). The normative structure <lb/>of science. In N. W. Storer (Ed.), The <lb/>sociology of science: Theoretical and <lb/>investigations (pp. 267-278). <lb/>Chicago, IL: University of Chicago Press. <lb/>Merton, R. K. (1988). The Matthew effect in <lb/>II: Cumulative advantage and the <lb/>symbolism of intellectual property. Isis, <lb/>79(4), 606-623. doi: 10.1086/354848 <lb/>J. (2011). Beyond the data. Science, <lb/>3 3 4(6053), 169-171. d o i: 10.1126/ <lb/>science.334.6053.169 <lb/>Metzger, W. P. (1990). The 1940 statement <lb/>principles on academic freedom and <lb/>tenure. Law and Contemporary Problems, <lb/>53(3), 3. doi: 10.2307/1191793 <lb/>Milem, J. F., Berger, J. B., &amp; Dey, E. L. (2000). <lb/>time allocation: A study of change over <lb/>years. The Journal of Higher Education, <lb/>71(4), 454-475. doi: 10.2307/2649148 <lb/>Miller, D. A. (1978). Criteria for appointment, <lb/>and retention of faculty in <lb/>graduate social work programs. Journal of <lb/>Education for Social Work, 14(2), 74-81. <lb/>doi: 10.1080/00220612.1978.10671503 <lb/>Mod e r n L a n g u a g e A s s o c i a t i o n. (2006). <lb/>S e l e c t e d f i n d i n g s f ro m t h e M L A&apos;s <lb/>2005 survey of tenure and promotion. <lb/>from http://apps.mla.org/pdf/ <lb/>Mutz, R., Bornmann, L., &amp; Daniel, H.-D. <lb/>(2015). Testing for fairness and predictive <lb/>validity of research funding decisions: A <lb/>multi-level multiple imputation for missing <lb/>approach using ex-ante and ex-post <lb/></listBibl>

			<page>80 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<listBibl>peer evaluation data from the Austrian <lb/>Science Fund. Journal of the Association for <lb/>Information Science and Technology, 66(11), <lb/>2321-2339. doi: 10.1002/asi.23315 <lb/>National Institutes of Health. (2013). Enhancing <lb/>p e e r re v i e w s u r v e y s u t s re p r t . <lb/>Retrieved from http://enhancing-peer-<lb/>Review_Report_2012.pdf <lb/>National Science Foundation. National <lb/>Science Foundation&apos;s merit review <lb/>Review and revisions. Retrieved from <lb/>http://www.nsf.gov/nsb/publications/2011/ <lb/>meritreviewcriteria.pdf <lb/>Nature. (2006). Overview: Nature&apos;s peer <lb/>review trial. Retrieved from http://www. <lb/>nature05535.html <lb/>R. S. (2005). What authors want <lb/>from journal reviewers and editors. <lb/>American Psychologist, 60, 661-662. doi: <lb/>10.1037/0003-066X.60.6.661 <lb/>Nylenna, M., Riis, P., &amp; Karlsson, Y. (1994). <lb/>Multiple blinded reviews of the same <lb/>two manuscripts: Effects of referee <lb/>characteristics and publication language. <lb/>o u r n a l o f t h e A m e r i c a n M e d i c a l <lb/>A s s o c i a t i o n , 2 7 2(2), 149-151. d o i: <lb/>10.1001/jama.272.2.149 <lb/>A. M. (1996). Tragic loss or good <lb/>riddance? The impending demise of <lb/>traditional scholarly journals. In R. P. <lb/>Peek &amp; G. B. Newby (Eds.), Scholarly <lb/>publishing: The electronic frontier (pp. 91-<lb/>101). Cambridge, MA: MIT Press. <lb/>M., &amp; Bornmann, L. (2010). Panel <lb/>peer review of grant applications: <lb/>do we know from research in social <lb/>psychology on judgment and decision-<lb/>making in groups? Research Evaluation, <lb/>19(4), 293-304. doi: 10.3152/095820210X <lb/>12809191250762 <lb/>T., &amp; Wilde, A. A. M. (2009). The <lb/>Hirsch-index: A simple, new tool for <lb/>assessment of scientific output <lb/>of individual scientists: The case of <lb/>Dutch professors in clinical cardiology. <lb/>Netherlands Heart Journal, 17(4), 145-<lb/>154. doi: 10.1007/BF03086237 <lb/>for Economic Co-operation and <lb/>Development. (2011a). Issue peer <lb/>Retrieved from http://www.oecd.org/ <lb/>innovation/policyplatform/48136766.pdf <lb/>Organisation for Economic Co-operation and <lb/>Development. (2011b). OECD issue <lb/>brief: Research organization evaluation. <lb/>from http://www.oecd.org/ <lb/>x man, A. D., Guyatt, G. H., Singer, J., <lb/>Goldsmith, G. H., Hutchison, B. G., Milner, <lb/>R. A., &amp; Streiner, D. L. (1991). Agreement <lb/>among reviewers of review articles. Journal <lb/>of Clinical Epidemiology, 44, 91-98. doi: <lb/>10.1016/0895-4356(91)90205-N <lb/>P a r l i a m e n t a r y O f f i c e o f S c i e n c e a n d <lb/>Technology. (2002). Peer review. Postnote, <lb/>182, 1-4. <lb/>Pendlebury, D. A. (2008). Using bibliometrics <lb/>in evaluating research. Philadelphia, PA: <lb/>Scientific, Research Department. <lb/></listBibl>

			<page>81 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>
			
			<listBibl>Perper, (1989). The loss of innovation: Peer <lb/>in multi-and interdisciplinary <lb/>research. Issues in Integrative Studies, 7, <lb/>21-56. <lb/>D. P., &amp; Ceci, S. J. (1982). Peer-<lb/>r e i e w p r a c t i c e s o f p s y c h o l o g i c a l <lb/>journals: The fate of articles, <lb/>again. Behavioral and Brain <lb/>Sciences, 5(2), 187-195. doi: 10.1017/ <lb/>S0140525X00011183 <lb/>Peters, H. P. F., &amp; van Raan, A. F. J. (1994). On <lb/>determinants of citation scores -A case <lb/>study in chemical engineering. Journal <lb/>of the American Society for Information <lb/>c i e n c e , 4 5, 39-49. d o i: 10.1002/ <lb/>(SICI)1097-4571(199401)45:1&lt;39::AID-<lb/>ASI5&gt;3.0.CO;2-Q <lb/>Polanyi, M. (1962). The republic of science. <lb/>M i n e r v a , 1(1), 54-73. d o i: 10.1007/ <lb/>BF01101453 <lb/>Popper, K. (1961). The logic scientific <lb/>discovery. London, England: Routledge &amp; <lb/>Kegan Paul. <lb/>Pouris, A. (1988). Peer review in scientifically <lb/>small countries. Management, 18(4), <lb/>333-340. doi: <lb/>tb00608.x <lb/>Powell, K. (2010). Making the cut. Nature, 467, <lb/>383-385. <lb/>Pratt, D. (1997). Reconceptualising the <lb/>of teaching in higher education. <lb/>Higher Education, 34, 23-33. <lb/>Pr i c e, D. J. (1963). i t t l e s c i e n c e , b i g <lb/>c i e n c e. N e w Yo r k, N Y: C o l u m b i a <lb/>University Press. <lb/>Rennie, D. (1986). Guarding the guardians: <lb/>conference on editorial peer review. <lb/>J o u r n a l o f t h e A m e r i c a n M e d i c a l <lb/>Association, 2391-2392. doi: <lb/>10.1001/jama.256.17.2391 <lb/>Rennie, D. (1998a). Freedom and responsibility <lb/>in medical publication: Setting the balance <lb/>right. Journal of the American Medical <lb/>A s s o c i a t i o n , 2 8 0(3), 300-302. d o i: <lb/>10.1001/jama.280.3.300 <lb/>Rennie, D. (1998b). The present state of medical <lb/>journals. The Lancet, 352, S18-S22. doi: <lb/>10.1016/S0140-6736(98)90295-1 <lb/>D. (2003). Editorial peer review: Its <lb/>development and rationale. In F. Godlee &amp; <lb/>T. Jefferson (Eds.), Peer review in health <lb/>sciences (pp. 1-13). London, England: <lb/>Publishing Group. <lb/>Councils UK. (2006). Report of the <lb/>Research Councils UK efficiency and <lb/>effectiveness of peer review project. <lb/>Retrieved from http://www.rcuk.ac.uk/ <lb/>rcukprreport.pdf <lb/>Research Councils UK. (2007). RCUK response <lb/>to the project report &amp; consultation on the <lb/>efficiency and effectiveness of peer review. <lb/>Retrieved from http://www.rcuk.ac.uk/ <lb/>responsereport.pdf <lb/>Research Evaluation and Policy Project. <lb/>(2005). Quantitative indicators for <lb/>research assessment -A literature review <lb/>(REPP discussion paper 05/1). Canberra, <lb/>Australia: Australian National University, <lb/></listBibl>

			<page>82 <lb/></page>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>
			
			<listBibl>Research School of Social Sciences, <lb/>Research Evaluation and Policy Project. <lb/>Research Information Network. (2010). Peer <lb/>review: A guide for researchers. <lb/>from http://www.rin.ac.uk/our-work/ <lb/>communicating-and-disseminating-<lb/>research/peer-review-guide-researchers <lb/>Research Information Network. (2011). E-journals: <lb/>Their use, value and impact. Retrieved <lb/>from http://www.rin.ac.uk/our-work/ <lb/>communicating-and-disseminating-research/ <lb/>e-journals-their-use-value-and-impact <lb/>A. (2000). Higher forms of nonsense. <lb/>European Review, 8(4), 467-485. doi: <lb/>10.1017/S1062798700005032 <lb/>Roberts, M. R. (2009). Realizing societal <lb/>benefit from academic Analysis <lb/>of the National Science Foundation&apos;s <lb/>b r o a d e r i m p a c t s c r i t e r i o n. S o c i a l <lb/>Epistemology, 23(3/4), 199-219. doi: <lb/>10.1080/02691720903364035 <lb/>R o y, R. (1985). F u n d i n g s c i e n c e: T h e <lb/>a l d e f e c t s o f p e e r-r e v i e w a n d a n <lb/>alternative to it. Science, Technology, <lb/>&amp; H u m a n Va l u e s , 5 2, 73-81. d o i: <lb/>10.1177/016224398501000309 <lb/>Royal Society. (1995). review -An <lb/>of recent developments. <lb/>from https://royalsociety.org/~/ <lb/>media/Royal_Society_Content/policy/ <lb/>Rymer, L. (2011). Measuring the impact <lb/>of research: The context for metric <lb/>development. Canberra, Australia: Group <lb/>of Eight Australia. <lb/>S a n d s t r ö m, U., &amp; H ä l l s t e n, M. (2007). <lb/>Persistent nepotism in peer-review. <lb/>74(2), 175-189. doi: <lb/>10.1007/s11192-008-0211-3 <lb/>S a v a g e, J. D. (1999). F u n d i n g s c i e n c e <lb/>America: Congress, universities, <lb/>and the politics of the academic pork <lb/>b a r re l. N e w Yo r k, N Y: C a m b r i d g e <lb/>Press. <lb/>S c a r p a, T. (2009, M a y). A s s e s s i n g a n d <lb/>advancing funding of biomedical research <lb/>benchmarking: Values and practices of <lb/>different countries. Paper presented at the <lb/>Sigtuna Project, Sigtuna, Sweden. <lb/>Sense about Science. (2010). Peer review <lb/>survey 2009: Full report. Retrieved from <lb/>files/Peer_Review/Peer_Review_Survey_ <lb/>Shadbolt, N., Brody, T., Carr, L., &amp; Harnad, <lb/>(2006). T h e o p e n r e s e a r c h w e b: <lb/>p r e v i e w o f t h e o p t i m a l a n d t h e <lb/>In N. Jacobs (Ed.), Open <lb/>access: Key strategic, technical and <lb/>economic aspects (pp. 195-208). Oxford, <lb/>England: Chandos. doi: 10.1016/B978-<lb/>Sieber, J. E. (2006). How can we research peer <lb/>review? Nature. doi: 10.1038/nature05006 <lb/>Smith, L. C. (1981). Citation analysis. Library <lb/>Trends, 30(1), 83-106. <lb/>Smith, R. (2003). The future of peer review. In F. <lb/>Godlee &amp; T. Jefferson (Eds.), Peer review <lb/>in health science (pp. 329-346). London, <lb/>BMJ Publishing Group. <lb/></listBibl>

			<page>83 <lb/></page>

			<listBibl>R. W. (2009). In search of an optimal <lb/>p e e r r e v i e w s y s t e m. J o u r n a o f <lb/>Participatory Medicine, 1, e13. <lb/>m i t h, R., &amp; R e n n i e, D. (1995). A n d <lb/>now, evidence based editing. <lb/>3 11(7009), 826-827. d o i: <lb/>bmj.311.7009.826 <lb/>Snodgrass, R. (2006). Single-double-<lb/>blind reviewing: An analysis of the <lb/>literature. Sigmod Record, 35, 8-21. doi: <lb/>10.1145/1168092.1168094 <lb/>Spier, R. (2002a). The history of the peer-<lb/>review process. Trends in Biotechnology, <lb/>2 0(8), 357-358. d o i: 10.1016/S0167-<lb/>7799(02)01985-6 <lb/>Spier, R. (2002b). Peer review and innovation. <lb/>and Engineering Ethics, 8, 99-<lb/>108. doi: 10.1007/s11948-002-0035-0 <lb/>Stricker, L. J. (1991). Disagreement among <lb/>j o u r n a l r e v i e w e r s: N o c a u s e f o r <lb/>undue alarm. Behavioral and Brain <lb/>Sciences, 14(1), 163-164. doi: 10.1017/ <lb/>S0140525X00065985 <lb/>Tatum, C., &amp; Wouters, P. (2013, November). <lb/>ACUMEN Portfolio: <lb/>evaluation of individual researchers. <lb/>Paper presented at euroCRIS Membership <lb/>Meeting, Porto, Portugal. Retrieved from <lb/>and-Wouters-ACUMEN@euroCRIS-<lb/>Travis, G. D. L., &amp; Collins, H. M. (1991). <lb/>New light on old boys: Cognitive and <lb/>institutional particularism in the peer <lb/>review system. Science, Technology <lb/>&amp; Human Values, 16(3), 322-341. doi: <lb/>10.1177/016224399101600303 <lb/>Van Arensbergen, P., van der Weijden, I., &amp; van <lb/>den Besselaar, P. (2014a). Academic talent <lb/>selection in grant review panels. In K. <lb/>I. van der Weijden, &amp; N. Asheulova <lb/>(Re)searching scientific careers <lb/>(pp. 25-54). St. Petersburg, Russia: IHST/ <lb/>RAS -Nestor-Historia -SSTNET/ESA. <lb/>Arensbergen, P., van der Weijden, I., &amp; van <lb/>den Besselaar, P. (2014b). Different views <lb/>talent: What are the talents we are <lb/>looking for in science? Research Evaluation, <lb/>23, 273-284. doi: 10.1093/reseval/rvu015 <lb/>Van den Besselaar, P., &amp; Leydesdorff, L. <lb/>Past performance, peer review <lb/>and project selection: A case study <lb/>in the social and behavioral sciences. <lb/>Evaluation, 18(4), 273-288. doi: <lb/>10.3152/095820209X475360 <lb/>Va n d e r M e u l e n, B., &amp; R i p, A. (2000). <lb/>Evaluation of societal quality of public <lb/>sector research in the Netherlands. <lb/>Research Evaluation, 9(1), 11-25. doi: <lb/>10.3152/147154400781777449 <lb/>Va n R a a n, A. F. J. (1996). A d v a n c e d <lb/>bibliometric methods as quantitative <lb/>of peer review based evaluation and <lb/>foresight exercises. Scientometrics, 36(3), <lb/>doi: 10.1007/BF02129602 <lb/>Raan, A. F. J. (2005). Fatal attraction: <lb/>Conceptual and methodological problems <lb/>n t h e r a n k i n g o f u n i v e r s i t i e s b y <lb/>bibliometric methods. Scientometrics, 62, <lb/>133-143. doi: 10.1007/s11192-005-0008-6 <lb/></listBibl>

			<note place="headnote">圖書資訊學刊 第14卷 第1期 (2016.6) <lb/></note>

			<listBibl>Van Rooyen, S., Black, N., &amp; Godlee, F. <lb/>(1999). Development of the review <lb/>quality instrument (RQI) for assessing <lb/>peer reviews of manuscripts. Journal of <lb/>Clinical Epidemiology, 52(7), 625-629. <lb/>doi: 10.1016/S0895-4356(99)00047-5 <lb/>Rooyen, S., Delamothe, T., &amp; Evans, S. <lb/>W. (2010). Effect on peer review of <lb/>telling reviewers that their signed reviews <lb/>might be posted on the web: Randomised <lb/>controlled trial. BMJ, c5729. doi: <lb/>10.1136/bmj.c5729 <lb/>Van Rooyen, S., Godlee, F., S., Smith, <lb/>R., &amp; Black, N. Effect of blinding <lb/>and unmasking on the quality of peer <lb/>A randomized trial. Journal of the <lb/>American Medical Association, 280(3), <lb/>234-237. doi: 10.1001/jama.280.3.234 <lb/>Ware, M. (2013). Peer review: An introduction <lb/>a n d g u i e. R e t r e v e d f r o m h t t p:// <lb/>www.tandf.co.uk/journals/pdf/PRC-<lb/>Wa r e, M., &amp; M o n k m a n, M. (2008). Peer <lb/>review in scholarly journals: Perspective <lb/>o f t h e s c h o l a r l y c o m m u n i t y -A n <lb/>international Retrieved from http:// <lb/>publishingresearchconsortium.com/ <lb/>index.php/112-prc-projects/research-<lb/>r e p o r t s/p e e r-r e v i e w-i n-s c h o l a r l <lb/>o u a e e a r c h-r e p o r t/142-p e e r-<lb/>o f-t h e-s c h o l a r l y-c o m m u n i t y-a n-<lb/>international-study <lb/>Waters, D. J. (2009, March 2). Archives, <lb/>e d i t i o n -m a k i n g , a n d t h e f u t u re o f <lb/>scholarly communication. Retrieved <lb/>from https://mellon.org/media/filer_ <lb/>public/30/9d/309de9a1-94fa-40fb-bb1f-<lb/>f087333e8658/d j w-a r c h i v e s-e d i t i o n-<lb/>We i n b a c h, R. W., &amp; R a n d o l p h, J. L. <lb/>(1984). R a t i n g s: P e e r r e v i e w f o r <lb/>tenure and promotion in professional <lb/>s c h o o l s. I m p r o v i n g C o l l e g e a n d <lb/>University Teaching, 32(2), 81-86. doi: <lb/>10.1080/00193089.1984.10533848 <lb/>Weingart, P. (2005). Impact of bibliometrics <lb/>upon the science system: Inadvertent <lb/>Scientometrics, 62(1), <lb/>117-131. d o i: 10.1007/s11192-005-<lb/>0007-7 <lb/>Weiser, I. (2012). Peer review in the tenure and <lb/>promotion process. College Composition <lb/>and Communication, 63(4), 645-672. <lb/>Weller, A. C. (2002). peer review: Its <lb/>strengths and weaknesses. Medford, NJ: <lb/>American Society for Information Science <lb/>and Technology. <lb/>Wenneras, C., &amp; Wold, A. (1997). Nepotism and <lb/>sexism in peer-review. Nature, 387(6631), <lb/>341-343. doi: 10.1038/387341a0 <lb/>S. (1998). Peer review of grant <lb/>applications: What do we know? The <lb/>Lancet, 352(9124), 301-305. doi: 10.1016/ <lb/>S0140-6736(97)11129-1 <lb/>Whitley, R., &amp; Gläser, J. (Eds.). (2007). The <lb/>changing governance of the sciences: <lb/>The advent of research evaluation <lb/>y s t e m s (Vo l s. 1-26). D o r d r e c h t, <lb/>Netherlands: Springer. <lb/></listBibl>

			<page>85 <lb/></page>

			<note place="headnote">同儕審查的起源、研究現況與展望 <lb/></note>
			
			<listBibl>T. W. (1970). A comprehensive survey <lb/>of undergraduate programs in English in <lb/>the United States. Retrieved from <lb/>files.eric.ed.gov/fulltext/ED044422.pdf <lb/>Williamson, A. (2003). What will happen to <lb/>review? Learned Publishing, 16(1), <lb/>15-20. doi: 10.1087/095315103320995041 <lb/>Wood, F. Q., &amp; Wessely, S. (2003). Peer review <lb/>of grant applications: A systematic review. <lb/>F. Godlee &amp; T. Jefferson (Eds.), Peer <lb/>review in health sciences (pp. <lb/>London, England: BMJ Publishing Group. <lb/>P. (1997). Citation cycles and peer <lb/>review cycles. Scientometrics, 38(1), 39-<lb/>55. doi: 10.1007/BF02461122 <lb/>Yalow, R. S. (1982). Competency testing <lb/>for reviewers and editors. Behavioral <lb/>and Brain Sciences, 5(2), 244-245. doi: <lb/>10.1017/S0140525X00011729 <lb/>P. (2006). Out of balance: Lecturers&apos; <lb/>p e r c e p t i o n s o f d i ff e r e n t i a l s t a t u s <lb/>and rewards in relation to teaching <lb/>a n d r e s e a r c h. Te a c h i n g i n H i g h e r <lb/>E d u c a t i o n , 11( 2 ) , 1 9 1 -2 0 2 . d o i : <lb/>10.1080/13562510500527727 <lb/>Ziman, J. (2000). Real science: What it is <lb/>and what it means. New York, NY: <lb/>University Press. doi: 10.1017/ <lb/>CBO9780511541391 <lb/>Zuckerman, H., &amp; Merton, R. K. (1971). <lb/>P a t t e r n s o f e v a l u a t i o n i n s c i e n c e: <lb/>Institutionalisation, structure and functions <lb/>the referee system. 9(1), 66-<lb/>100. doi: 10.1007/BF01553188 <lb/>(投稿日期Received: 2015/5/19 接受日期Accepted: 2016/3/14) </listBibl>


	</text>
</tei>
